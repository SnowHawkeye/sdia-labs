{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "### Noms et Prénoms du binome :\n",
        "- Hadrien SALEM\n",
        "- Emilie SALEM\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "# TP en Watermarking - TP2\n",
        "\n",
        "---\n",
        "\n",
        "## Patrick Bas, CNRS, CRIStAL\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Tatouage par également de spectre et attaques de sécurité\n",
        "\n",
        "### 2.1 Notations et rappels:\n",
        "\n",
        "Les notations sont identiques à celles vues en cours. Le procédé d'insertion est le schéma par étalement de spectre vu en cours.\n",
        "\n",
        "* X = matrice de $N_{i}$ vecteurs originaux de taille $N_{v}$ ($N_{i}$ colonnes, $N_{v}$ lignes). $N_{i}$ représente par exemple le nombre de contenu traités, et $N_{v}$ le nombre de composantes tatouées par contenu. **Note**: chaque colonne de X peut par exemple représenter des composantes d'une image.\n",
        "* $N_{o}$ représente le nombre de contenus tatoués observés par l'adversaire et utilisés pour construire son attaque\n",
        "* $N_{i}$ représente le nombre de contenus tatoués utilisés pour calculer pratiquement le taux d'erreur (voir BER)\n",
        "* Y = matrice de contenus tatoués\n",
        "* Z = matrice de contenus tatoués et perturbés\n",
        "* k clé secrète de norme unitaire\n",
        "* $m_{1}$: bit inséré, converti en +1, -1 \n",
        "* $\\alpha$: paramètre de distorsion\n",
        "* BER: Bit Error Rate, taux d'erreur binaire ou encore probabilité d'erreur empirique de décodage\n",
        "* DWR: « Document to Watermark Ratio » $DWR=10\\log_{10}(\\sum x_{i}^{2}/\\sum w_{i}^{2})$, permet de mesurer la distorsion ($DWR=0$ $\\Leftrightarrow$ $\\sigma_{X}^{2}=\\sigma_{W}^{2}$ ). Permet de mesurer la distortion. Distortion nulle $DWR=\\infty$, distortion importante $DWR \\rightarrow 0$ \n",
        "\n",
        "#### Rappels:\n",
        "* L'objectif du récepteur est de bien décoder $m_{1}$, possiblement en ayant une distortion qui ne soit pas trop importante\n",
        "* Ici, les objectifs de l'adversaire sont d'estimer la clé k puis d'effacer le message inséré. Pour s'assurer que l'adversaire a bien réussi à estimer la clé, il calculera la correlation normalisée entre le vecteur k et son estimation.\n",
        "\n",
        "**N'oubliez pas d'exporter votre TP en html lors de sa remise**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import erf\n",
        "from sklearn.decomposition import FastICA"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Scénario 1: Attaque à Messages connus, 1 bit\n",
        "* Mise en route: Quel est le BER cible de l'adversaire ?\n",
        "* Mettre en place l'attaque liée à ce scénario\n",
        "* Etudier l'impact de $N_{o}$ et de $\\alpha$ sur le BER après attaque"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Réponses \n",
        "\n",
        "- Le BER cible de l'adversaire est de $0.5$ : en effet, si le contenu n'est pas tatoué, on fait 1 erreur sur 2 lors du décodage du message. Autrement dit, on ne peut plus retrouver le message inséré (puisque le message inséré a été effacé).\n",
        "- Voir code ci-dessous, en particulier l'implémentation de `hatk` en utilisant la formule : \n",
        "  $$\n",
        "  \\hat k_1 = \\frac{1}{\\alpha N_o} \\sum - (-1)^m y_i\n",
        "  $$\n",
        "- Comme on peut le voir sur la courbe \"`BER après attaque en fonction du nombre No d'observations utilisées`\", plus $N_o$ augmente plus le BER se rapproche de la valeur cible $0.5$. En effet, plus on fait d'observations, mieux on est capable d'estimer la valeur de $k$ (moyenne empirique) ce qui permet de retirer le message $m$ efficacement.\n",
        "- La courbe \"`BER après attaque en fonction du coefficient alpha`\" montre que plus le coefficient $\\alpha$ augmente, plus on semble se rapprocher de la valeur cible $0.5$. Cependant, la variation est assez irrégulière: dans ce scénario, $\\alpha$ ne semble pas beaucoup influencer la prédiction à faire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "Nv = 100 # Size of the vector\n",
        "Ni = 10000 # Max number of observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "def ber(Y,m,k):# Compute the Bit Error Rate between message m and the extracted message from Y using key k\n",
        "    c = np.sign(np.dot(Y.T,k))\n",
        "    return np.sum(c != m)/np.float(Ni)\n",
        "\n",
        "def norm_corr(hatk,k): # Correlation between k and its estimate\n",
        "    hatk = hatk / np.sqrt(np.dot(hatk.T,hatk)) # Normalize\n",
        "    corrN = np.abs(np.dot(hatk.T,k))/(np.linalg.norm(hatk)*np.linalg.norm(k)) # Compute the Normalised correlation\n",
        "    return corrN\n",
        "\n",
        "def do_process(alpha,No):\n",
        "    \n",
        "    print('alpha: ',alpha)\n",
        "    print('No: ',No)\n",
        "\n",
        "    X = np.random.randn(Nv,Ni) # Generate Ni random host vectors\n",
        "    k = np.random.randn(Nv,1) # Generate the Watermark\n",
        "    k = k / np.sqrt(np.dot(k.T,k)) # Normalize the watermark\n",
        "\n",
        "    m1 = np.ones((Ni,1)) # Scenario with Known Messages: generate only ones, to be changed for the WOA attack!!!\n",
        "\n",
        "    K = np.dot(k,m1.T) # Generate the matrix of watermarks (each column contains m1_i*k)\n",
        "\n",
        "    W = alpha*K\n",
        "\n",
        "    Y = X + W # perform embedding\n",
        "\n",
        "    DWR = 10*np.log10(Nv/alpha**2) # Set the Document to Watermark Ratio, in dB\n",
        "\n",
        "    print('DWR: ',DWR,' dB')\n",
        "\n",
        "    cY = np.sign(np.dot(Y.T,k)) # Computation of the decoded 'bits' (here -1 or +1)\n",
        "    print('practical bit error rate:')\n",
        "    print(np.sum(cY != m1)/np.float(Ni)) \n",
        "\n",
        "    # Attack\n",
        "    Y_obs = Y[:,:No]\n",
        "    \n",
        "    hatk = np.zeros(Nv)\n",
        "    for v in range(Nv): # For each component of the key\n",
        "        for i in range(No): # Sum on observations\n",
        "            hatk[v] += -((-1)**m1[i])*Y_obs[v][i]/(alpha*No)\n",
        "    hatk = hatk / np.sqrt(np.dot(hatk.T,hatk)) # We need to Normalize\n",
        "    \n",
        "    corrN = np.abs(np.dot(hatk.T,k))/(np.linalg.norm(hatk)*np.linalg.norm(k)) # Compute the Normalised correlation\n",
        "    print('Normalised correlation between the true key and the estimated key')\n",
        "    print(corrN)\n",
        "\n",
        "    hatk = np.reshape(hatk,(Nv,1)) # We need to reshape\n",
        "\n",
        "    YA = Y - alpha*np.dot(hatk,m1.T) # KMA: perform the removal attack\n",
        "    practical_ber = ber(YA,m1,k)\n",
        "    print('practical bit error rate after security attack')\n",
        "    print(practical_ber)\n",
        "    print('\\n\\n')\n",
        "    return practical_ber, corrN\n",
        "    \n",
        "\n",
        "alpha = 2 # Tune the power of the watermark here\n",
        "\n",
        "ber_list_No = []\n",
        "corrN_list_No = []\n",
        "No_list = np.arange(100,2000,100)\n",
        "\n",
        "for No in No_list:\n",
        "    practical_ber, corrN = do_process(alpha,No)\n",
        "    ber_list_No.append(practical_ber)\n",
        "    corrN_list_No.append(corrN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"BER après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Nombre d'observations No\")\n",
        "plt.ylabel(\"BER (en bits)\")\n",
        "plt.plot(No_list, ber_list_No)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Corrélation normalisée après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Nombre d'observations No\")\n",
        "plt.ylabel(\"Corrélation normalisée\")\n",
        "plt.plot(No_list, corrN_list_No)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "ber_list_alpha = []\n",
        "corrN_list_alpha = []\n",
        "alpha_list = np.arange(1,20)\n",
        "\n",
        "for alpha in alpha_list:\n",
        "    practical_ber, corrN_alpha = do_process(alpha,No=1000)\n",
        "    ber_list_alpha.append(practical_ber)\n",
        "    corrN_list_alpha.append(corrN_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"BER après attaque en fonction du coefficient alpha\")\n",
        "plt.xlabel(\"Coefficient alpha\")\n",
        "plt.ylabel(\"BER (en bits)\")\n",
        "plt.plot(alpha_list, ber_list_alpha)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Corrélation normalisée après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Coefficient alpha\")\n",
        "plt.ylabel(\"Corrélation normalisée\")\n",
        "plt.plot(alpha_list, corrN_list_alpha)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Scénario 2, Attaque à messages inconnus, 1bit\n",
        "* Note: la fonction `np.linalg.eig` peut être utilisée pour effectuer une décomposition en valeurs et vecteurs propres.\n",
        "* Note: pour effacer le message inséré, il conviendra au préalable d'estimer le bit inséré, cela peut se faire via `m_est = np.sign(np.dot(Y.T,hatk))` où `hatk` est la clé estimée\n",
        "* Mettre en place l'attaque\n",
        "* Etudier l'impact de $N_{o}$ et de $\\alpha$ sur le BER après attaque"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Réponses\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# 2dn scenario, scenario with KMA \n",
        "print('2nd Scenario')\n",
        "\n",
        "def do_process(alpha,No):\n",
        "    \n",
        "    print('alpha: ',alpha)\n",
        "    print('No: ',No)\n",
        "\n",
        "    X = np.random.randn(Nv,Ni) # Generate Ni random host vectors\n",
        "    k = np.random.randn(Nv,1) # Generate de Watermark\n",
        "    k = k / np.sqrt(np.dot(k.T,k)) # Normalize the watermark\n",
        "\n",
        "    m1 = np.sign(np.random.randn(Ni,1)) #Scenario with unknow messages, first bit\n",
        "\n",
        "    K = np.dot(k,m1.T) # Generate the matrix of watermarks (each column contains m1_i*k)\n",
        "\n",
        "    W = alpha*K\n",
        "\n",
        "    Y = X + W # perform embedding\n",
        "\n",
        "    # Attack\n",
        "    Y_obs = Y[:,:No]\n",
        "    \n",
        "    hatk = np.zeros(Nv)# To change\n",
        "\n",
        "    cov = np.cov(Y_obs)\n",
        "    eigvals, eigvects = np.linalg.eig(cov)\n",
        "\n",
        "    idx = eigvals.argsort()[::-1]   \n",
        "    eigvals = eigvals[idx]\n",
        "    eigvects = eigvects[:,idx]\n",
        "    \n",
        "    hatk = eigvects[:,0]\n",
        "    \n",
        "    hatk = np.reshape(hatk,(Nv,1)) #You might need to reshape the estimated key\n",
        "\n",
        "    corrN = norm_corr(hatk,k)# To ease the writing we use the norm_corr function\n",
        "\n",
        "    print('Normalised correlation between the true key and the estimated key')\n",
        "    print(corrN)\n",
        "\n",
        "    m_est = np.sign(np.dot(Y.T,hatk))\n",
        "    YA = Y - alpha*np.dot(hatk,m_est.T) # KMA: perform the removal attack\n",
        "\n",
        "    print('bit error rate after security attack')\n",
        "    practical_ber = ber(YA,m1,k)\n",
        "    print(practical_ber)\n",
        "    print('\\n\\n')\n",
        "    return practical_ber, corrN\n",
        "\n",
        "\n",
        "    \n",
        "alpha = 2 # Tune the power of the watermark here\n",
        "\n",
        "ber_list_No = []\n",
        "corrN_list_No = []\n",
        "No_list = np.arange(100,2000,100)\n",
        "\n",
        "for No in No_list:\n",
        "    practical_ber, corrN = do_process(alpha,No)\n",
        "    ber_list_No.append(practical_ber)\n",
        "    corrN_list_No.append(corrN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"BER après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Nombre d'observations No\")\n",
        "plt.ylabel(\"BER (en bits)\")\n",
        "plt.plot(No_list, ber_list_No)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Corrélation normalisée après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Nombre d'observations No\")\n",
        "plt.ylabel(\"Corrélation normalisée\")\n",
        "plt.plot(No_list, np.ravel(corrN_list_No))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "ber_list_alpha = []\n",
        "corrN_list_alpha = []\n",
        "alpha_list = np.arange(1,20)\n",
        "\n",
        "for alpha in alpha_list:\n",
        "    practical_ber, corrN_alpha = do_process(alpha,No=1000)\n",
        "    ber_list_alpha.append(practical_ber)\n",
        "    corrN_list_alpha.append(corrN_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"BER après attaque en fonction du coefficient alpha\")\n",
        "plt.xlabel(\"Coefficient alpha\")\n",
        "plt.ylabel(\"BER (en bits)\")\n",
        "plt.plot(alpha_list, ber_list_alpha)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Corrélation normalisée après attaque en fonction du nombre No d'observations utilisées\")\n",
        "plt.xlabel(\"Coefficient alpha\")\n",
        "plt.ylabel(\"Corrélation normalisée\")\n",
        "plt.plot(alpha_list, np.ravel(corrN_list_alpha))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Scénario 3: Attaque à messages inconnus, 2 bits\n",
        "* Vérifier que l'attaque précédente ne permet pas d'estimer les deux clés. \n",
        "* Estimer au moins l'une des clés utilisée\n",
        "    * Note: on pourra utiliser l'algorithme `FastICA` pour estimer les deux composantes indépendantes \n",
        "    * Pour cela on pourra appeler la fonction fastica en spécifiant que l'analyse en composantes indépendantes s'effectuera sur un sous espace engendré par les *deux premières composantes principales* (`n_components=2`), et en récupérant les colonnes de la matrice de mélange A (obtenue via `ica.mixing_`) estimé par l'algorithme.\n",
        "    * Vérifier, à l'aide de la corrélation normalisée, que cette méthode permet d'estimer la clé `k1`\n",
        "* Mettre en place l'attaque qui permet d'effacter un bit sur les deux\n",
        "* Etudier l'impact de $N_{o}$ et de $\\alpha$ sur le BER après attaque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# 3rd scenario, 2 bits\n",
        "print('3rd scenario, 2bits')\n",
        "\n",
        "m1 = np.sign(np.random.randn(Ni,1))#Scenario with unknow messages, first bit\n",
        "m2 = np.sign(np.random.randn(Ni,1))#Scenario with unknow messages, second bit\n",
        "\n",
        "k1 = np.random.randn(Nv,1) # Generate de Watermark\n",
        "k1 = k1 / np.sqrt(np.dot(k1.T,k1)) # Normalize the watermark\n",
        "\n",
        "k2 = np.random.randn(Nv,1) # Generate de Watermark\n",
        "k2 = k2 / np.sqrt(np.dot(k2.T,k2)) # Normalize the watermark\n",
        "\n",
        "def do_process(alpha,No):\n",
        "    \n",
        "    print('alpha: ',alpha)\n",
        "    print('No: ',No)\n",
        "\n",
        "    X = np.random.randn(Nv,Ni) # Generate Ni random host vectors\n",
        "\n",
        "    K = np.dot(k1,m1.T) + np.dot(k2,m2.T) # Generate the matrix of watermarks (each column contains m1_i*k)\n",
        "\n",
        "    W = alpha*K\n",
        "\n",
        "    Y = X + W # perform embedding\n",
        "\n",
        "    \n",
        "    Y_obs = Y[:,:No]\n",
        "    # TO DO\n",
        "    \n",
        "    # hatk_1 = TO DO\n",
        "    hatk_1 = np.zeros(Nv)# To change\n",
        "    \n",
        "    hatk_1 = hatk_1/np.linalg.norm(hatk_1)\n",
        "    hatk_1 = np.reshape(hatk_1,(Nv,1))\n",
        "\n",
        "    corrN_1 = norm_corr(hatk_1,k1) # Compute the Normalised correlation\n",
        "    print('Normalised correlation between the estimated key and k1')\n",
        "    print(corrN_1)\n",
        "\n",
        "    corrN_2 = norm_corr(hatk_1,k2) # Compute the Normalised correlation\n",
        "    print('Normalised correlation between the estimated key and k2')\n",
        "    print(corrN_2)\n",
        "\n",
        "    # Perform the attack\n",
        "    # To do\n",
        "    YA_1 = np.zeros((Nv,Ni))# To change   \n",
        "    \n",
        "    \n",
        "    print('bit error rate after security attack for the first bit')\n",
        "    print(ber(YA_1,m1,k1))\n",
        "\n",
        "    print('bit error rate after security attack for the second bit')\n",
        "    print(ber(YA_1,m2,k2))\n",
        "    print('\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "alpha = 2 # Tune the power of the watermark here\n",
        "\n",
        "# One example, can be used to draw plots\n",
        "for No in range(100,2000,100):\n",
        "    do_process(alpha,No)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Pour conclure: Etude de la robustesse\n",
        "* Calculer le taux d'erreur (BER pour Bit Error Rate) théorique après ajout de bruit (voir cours)\n",
        "* Etudier l'évolution de la robustesse (via le BER) en fonction de la distortion (via le DWR) \n",
        "* Quel compromis observe-t-on entre la sécurité et la robustesse?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "# Stéganalyse par apprentissage\n",
        "## Mise en route:\n",
        "* Récupèrer les caractéristiques ici: https://nextcloud.univ-lille.fr/index.php/s/i6xr4JykqAASapN\n",
        "* On charge les caractéristiques extraites à partir des images Cover et Stego pour d=3 (dimension de l'histogramme multivarié) et T=3 (seuil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "cover = np.loadtxt('Features/cover-spam-N=3-T=3.csv')\n",
        "stego = np.loadtxt('Features/stego-0.20-lsb-spam-N=3-T=3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "print(cover.shape)\n",
        "print(stego.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "**Quelle est la dimension des caractéristiques ? Pourquoi ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "**Entrainer un classifieur linéaire avec 5000 images en apprentissage et en test (effectuer une permutation pseudo-aléatoire des images avant l'apprentissage)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "**Vérifier l'impact de l'apprentissage par paires**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "**Effectuer plusieurs entrainements/test successifs sur des ensembles d'apprentissage et de test différents (permutations différentes), commentez la variabilité**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "**Comparer avec les caractéristiques produites pour N = 2 et T = 4 (fournies), expliquer la différence de performance**"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
