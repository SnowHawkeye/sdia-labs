{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "# Probability 2 (Master Data science, University of Lille) / CMF (Centrale Lille, G3 SDIA)\n",
        "\n",
        "---\n",
        "\n",
        "## Lab 2 - Queues, Metropolis-Hastings and simulated annealing\n",
        "\n",
        "---\n",
        "\n",
        "## Student 1 : Hadrien Salem\n",
        "## Student 2 : Emilie Salem\n",
        "\n",
        "---\n",
        "\n",
        "## Guidelines (read carefully before starting)\n",
        "\n",
        "**Objectives**: numerically simulate queues, implement an example of a Metropolis-Hasting algorithm and simulated annealing.\n",
        "\n",
        "**Setup**: after retrieving the resources for the lab on moodle:\n",
        "- place the .zip archive in a local folder (Computer -> Documents/Python/);\n",
        "- unzip the archive .zip;\n",
        "- rename the folder with the convention lab2_Name1_Name2\n",
        "- duplicate the notebook file and rename it lab2_Name1_Name2.ipynb;\n",
        "- [**optional, possibly needed if working from Centrale's machines**]\n",
        "    - create a `lab2` conda environment from the provided `requirement.txt` file\n",
        "    ```bash\n",
        "    conda create --name=lab2 --file=requirement.txt\n",
        "    conda activate lab2\n",
        "    # do not forget to deactivate the environment if needed\n",
        "    # you can remove the environment once you are done\n",
        "    conda env remove --name=lab2\n",
        "    ```\n",
        "    - launch jupyter notebook (the python environment will be the one from the conda environment `lab2`)\n",
        "- at the end of the session, do not forget to transfer your work to your own network space if you are working on a machine from the school (do not leave your work on the C: drive).\n",
        "\n",
        "**Assessment** &#8594; grade /20 (possibly converted later on to a grade ranging from F to A (A+))\n",
        "\n",
        "This lab session will be evaluated, based on your answer to the exercises reported in a Jupyter notebook (e.g., this one) and any additional `.py` file produced. In particular:\n",
        "\n",
        "- make sure the notebook you produce is properly annotated: each exercise should be introduced by a short sentence summarizing its context. Concisely answer each question from the guideline. \n",
        "- **relate the numerical results to the theory covered during the lecture** whenever appropriate;\n",
        "- **codes without any explanations (in a text cell) will not be considered as a complete answer**, and will only be attributed a fraction of the grade attributed to the question.\n",
        "- any code produced should be commented whenever appropriate;\n",
        "- include appropriate axis labels and a relevant title to each figure reported in the notebook;\n",
        "- **document any function you introduce (using docstrings)**, and comment your code whenever appropriate (see, *e.g.*, [PEP 8 style recommendations](https://www.python.org/dev/peps/pep-0008/)). \n",
        "     - use a reference docstring style, *e.g.*, the [google docstring style](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html).\n",
        "- **give a clear structure to your notebook**: longer theoretical explanations should be reported in markdown cells. Include LaTeX equations to improve the clarity of the document.\n",
        "\n",
        "**Additional evaluation criteria**:\n",
        "- Code clarity / conciseness / documentation\n",
        "- Comment quality / overall presentation\n",
        "\n",
        "## <a name=\"content\">Contents</a>\n",
        "- [Exercise 1: Simulating $M/M/1/\\infty$ and $M/M/1/K$ queues](attachment:./#ex1)\n",
        "- [Exercise 2: Drawing samples from the Ising model with the Metropolis-Hasings algorithm](attachment:./#ex2)\n",
        "- [Exercise 3: Simulated annealing for the *traveling salesman* problem](attachment:./#ex3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "---\n",
        "## <a name=\"ex1\">Exercise 1: Simulating $M/M/1/\\infty$ and $M/M/1/K$ queues</a> [(&#8593;)](attachment:./#content)\n",
        "\n",
        "This exercise will focus on simulating an $M/M/1/\\infty$ and an $M/M/1/K$ queue to illustrate some of the results covered in lecture 5. <!--in Chapter 2 and in TD.3-->\n",
        "\n",
        "In the following, the parameter of the exponential distributions governing the inter-arrival and service times will be denoted $\\lambda$ and $\\mu$ respectively, with $0< \\lambda < \\mu $. The time instants at which changes occur in the process $X(t)$ will be denoted by $T_n$ for $n \\in \\mathbb{N}$. We further define:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\rho = \\frac{\\lambda}{\\mu}, \\; X_n = X(T_n).\n",
        "\\end{equation}\n",
        "\n",
        "### $M/M/1/\\infty$-queue\n",
        "\n",
        "1\\. a) Using the lecture notes, implement a function to simulate a trajectory $X(t)$ of an $M/M/1/\\infty$ process, where $X(t)$ represents the number of customers in the system at time $t$. <!--  from Chapter 2, Section 2.3.1 -->\n",
        "\n",
        "> *Remark*: the signature of the function could be of the form:\n",
        "``` python\n",
        "def run_mm1inf(lambd: float, mu: float, rng, niter: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        lambd (float): birth rate.\n",
        "        mu (float): death rate\n",
        "        rng (int): random seed (or random generator).\n",
        "        niter (int): number of changes (events) in \n",
        "                     the process.\n",
        "    Raises:\n",
        "        ValueError: error triggered if lambd <= 0.\n",
        "        ValueError: error triggered if mu <= 0.\n",
        "    Returns:\n",
        "        X (array_like): trajectory (X(t_n)).\n",
        "        T (array_like): time instants at which a change in \n",
        "                        the process occurs (t_n).\n",
        "    \"\"\" \n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "Let us implement the function as it is described above.\n",
        "\n",
        "We are modelling a birth/death process, and we will use the corresponding theoretical results.\n",
        "We need to proceed incrementally, where at each step we compute:\n",
        "- The time at which an event (birth or death) will occur.\n",
        "    - If there is one or more customer in the queue, it is given by a random variable following an **exponential law** of parameter $\\lambda + \\mu$.\n",
        "    - If there is no customer in the queue, no \"death\" can occur, so the time is given by a random variable following an **exponential law** of parameter $\\lambda$.\n",
        "- The probability that this event is a birth is given by:\n",
        "    -  $\\frac{\\lambda}{\\lambda + \\mu}$ if there is one or more customer in the system.\n",
        "    -  $1$ if there is no customer in the queue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def run_mm1inf(lambd, mu, rng, niter):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        lambd (float): birth rate.\n",
        "        mu (float): death rate\n",
        "        rng (int): random seed (or random generator).\n",
        "        niter (int): number of changes (events) in \n",
        "                     the process.\n",
        "    Raises:\n",
        "        ValueError: error triggered if lambd <= 0.\n",
        "        ValueError: error triggered if mu <= 0.\n",
        "    Returns:\n",
        "        X (array_like): trajectory (X(t_n)).\n",
        "        T (array_like): time instants at which a change in \n",
        "                        the process occurs (t_n).\n",
        "    \"\"\" \n",
        "\n",
        "    # Raises errors if mu and lambd are not valid\n",
        "    if lambd < 0 or mu < 0: raise ValueError(\"Lambda and mu must be strictly positive.\")\n",
        "\n",
        "    # Arrays that will be returned\n",
        "    X = np.zeros(niter)\n",
        "    T = np.zeros(niter)\n",
        "\n",
        "    # Initialisation\n",
        "    random = np.random.default_rng(seed=rng)\n",
        "    X[0] = 0\n",
        "    T[0] = 0\n",
        "\n",
        "    for i in range(1,niter) :\n",
        "        # If there is no customer, birth in necessarily selected\n",
        "        if X[i-1] == 0:\n",
        "            event_time_increment = random.exponential(1 / lambd)\n",
        "            T[i] = T[i-1] + event_time_increment\n",
        "            X[i] = X[i-1] + 1\n",
        "\n",
        "        else :\n",
        "            # Generating the time increment according to an exponential law\n",
        "            event_time_increment = random.exponential(1/ (lambd + mu))\n",
        "            T[i] = T[i-1] + event_time_increment\n",
        "\n",
        "            # Selection of birth or death\n",
        "            birth_probability = lambd/(lambd+mu)\n",
        "            r = random.binomial(1, birth_probability)\n",
        "            if r == 1 : X[i] = X[i-1] + 1\n",
        "            else : X[i] = X[i-1] - 1\n",
        "\n",
        "    return X,T"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "b) Display the generated trajectory of the process for $(\\lambda,\\mu) = (5, 6)$ (e.g., use only the last 100 samples of the trajectory to obtain a representative illustration).\n",
        "\n",
        "> *Hint*: use the function `step` from the matlplotlib library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initializing parameters\n",
        "niter = 1000\n",
        "lambd, mu = 5, 6\n",
        "rng = 0\n",
        "\n",
        "# Generating the trajectory\n",
        "X,T = run_mm1inf(lambd, mu, rng, niter)\n",
        "\n",
        "# Displaying the last 100 samples\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.step(T[-100:],X[-100:])\n",
        "plt.xlabel(\"Time at which a change in the process happens\")\n",
        "plt.ylabel(\"Number of customers\")\n",
        "plt.title(f\"Last 100 samples of a trajectory of {niter} steps with parameters (lambda, mu) = ({lambd},{mu})\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Comment\n",
        "\n",
        "We can observe that the number of customers remains close to 0 throughout the simulation. That's because we chose a birth rate that is lower than the death rate: since customers leave the queue faster than they arrive, the number of people waiting in the queue rarely goes up."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "2\\. a) Display on the same graph the normalized histogram of $(X_n)_n$ and the stationary distribution $\\pi$ defined by (see Proposition 2.1 in lecture 5)\n",
        "\n",
        "\\begin{equation}\n",
        "    (\\forall i \\in \\mathbb{N}), \\; \\pi(i) = (1 - \\rho)\\rho^i.\n",
        "\\end{equation}\n",
        "\n",
        "What does this graph illustrate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Computing the stationary distribution pi\n",
        "rho = lambd / mu\n",
        "pi_i = lambda i: (1-rho)*(rho**i) \n",
        "lin = np.arange(0, 25)\n",
        "pi_distrib = pi_i(lin)\n",
        "\n",
        "print(pi_distrib.shape)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "# Displaying the normalized histogram of X_n\n",
        "X_distrib = np.bincount(X.astype(int))\n",
        "plt.stem(X_distrib/niter)\n",
        "\n",
        "# Displaying pi\n",
        "plt.stem(pi_distrib, linefmt=\"green\", markerfmt=\"go\")\n",
        "\n",
        "plt.title(\"Normalized histogram of X_n and stationary distribution pi\")\n",
        "plt.legend([\"Normalized histogram of X_n\",\"Stationary distribution pi\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Comment\n",
        "\n",
        "We can observe that the empirical curve obtained with the simulation is close to the theoretical distribution, as expected. This is also further illustrates that the number of customers tends to stay close to 0."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "b) Empirically evaluate the average number of customers, whose value should be close close to the theoretical value $\\frac{\\rho}{1-\\rho}$ (see Definition 2.3 p. 2 in lecture 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Computing the average number of customers and the theoretical value\n",
        "avg_customers = X.mean()\n",
        "theo_value = rho / (1-rho)\n",
        "\n",
        "# Comparing it to the theoretical value\n",
        "print(f\"Average number of customers for this simulation: {avg_customers}\")\n",
        "print(f\"Theoretical value: {theo_value}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "# Comment\n",
        "\n",
        "As expected, the average number of customers is close to the theoretical value of 5. Again, we can note that this low value is coherent with the problem at hand."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "### $M/M/1/K$\n",
        "\n",
        "Consider the case where the size of the capacity service $K$ is finite, i.e., where the system can only accommodate up to $K$ customers. In comparison with the previous case, any new customer trying to enter the system at a time instant $t$ will be systematically rejected if $X(t) = K$.\n",
        "\n",
        "3\\. a) Propose a variant of the function developed in 1.a) to simulate a trajectory of an $M/M/1/K$ process."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "The function is very similar to the one developed for the $M/M/1/\\infty$ queue. The only change is that, in the event of a birth, we need to check if the maximum capacity $K$ has been reached. In that case, the number of customers remains the same since the incoming customer is rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "def run_mm1k(lambd, mu, rng, niter, K):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        lambd (float): birth rate.\n",
        "        mu (float): death rate\n",
        "        rng (int): random seed (or random generator).\n",
        "        niter (int): number of changes (events) in \n",
        "                     the process.\n",
        "        K (int): capacity service of the queue.\n",
        "    Raises:\n",
        "        ValueError: error triggered if lambd <= 0.\n",
        "        ValueError: error triggered if mu <= 0.\n",
        "    Returns:\n",
        "        X (array_like): trajectory (X(t_n)).\n",
        "        T (array_like): time instants at which a change in \n",
        "                        the process occurs (t_n).\n",
        "    \"\"\" \n",
        "\n",
        "    # Raises errors if mu and lambd are not valid\n",
        "    if lambd < 0 or mu < 0: raise ValueError(\"Lambda and mu must be strictly positive.\")\n",
        "\n",
        "    # Arrays that will be returned\n",
        "    X = np.zeros(niter)\n",
        "    T = np.zeros(niter)\n",
        "\n",
        "    # Initialisation\n",
        "    random = np.random.default_rng(seed=rng)\n",
        "    X[0] = 0\n",
        "    T[0] = 0\n",
        "\n",
        "    for i in range(1,niter) :\n",
        "        # If there is no customer, birth in necessarily selected\n",
        "        if X[i-1] == 0:\n",
        "            event_time_increment = random.exponential(1 / lambd)\n",
        "            T[i] = T[i-1] + event_time_increment\n",
        "            X[i] = X[i-1] + 1\n",
        "\n",
        "        else :\n",
        "            # Generating the time increment according to an exponential law\n",
        "            event_time_increment = random.exponential(1/ (lambd + mu))\n",
        "            T[i] = T[i-1] + event_time_increment\n",
        "\n",
        "            # Selection of birth or death\n",
        "            birth_probability = lambd/(lambd+mu)\n",
        "            r = random.binomial(1, birth_probability)\n",
        "            if r == 1 : \n",
        "                # Checking if the queue is saturated\n",
        "                if X[i-1] == K:\n",
        "                    X[i] = X[i-1]\n",
        "                else :\n",
        "                    X[i] = X[i-1] + 1\n",
        "            else : X[i] = X[i-1] - 1\n",
        "\n",
        "    return X,T"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "b) Display the trajectory of the process for $(\\lambda,\\mu, K) = (5, 6, 3)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Initializing parameters\n",
        "niter = 1000\n",
        "lambd, mu, K = 5, 6, 3\n",
        "rng = 0\n",
        "\n",
        "# Generating the trajectory\n",
        "X,T = run_mm1k(lambd, mu, rng, niter, K)\n",
        "\n",
        "# Displaying the last 100 samples\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.step(T[-100:],X[-100:])\n",
        "plt.xlabel(\"Time at which a change in the process happens\")\n",
        "plt.ylabel(\"Number of customers\")\n",
        "plt.title(f\"Last 100 samples of a trajectory of {niter} steps with parameters (lambda, mu, K) = ({lambd},{mu},{K})\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "## Comment\n",
        "We see that the number of customers never exceeds 3, which is the expected behaviour of our simulation algorithm.\n",
        "Just like before, there seems to be a tendency to keep a \"low\" number of customers because the birth rate is lower than the death rate. This observation will be confirmed in the following segment."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "4\\. a) Display on the same graph the normalized histogram of $X_n$ and the stationary distribution $\\pi$ defined as\n",
        "\n",
        "$$\n",
        "    (\\forall i \\in \\mathbb{N}), \\; \\pi(i) =\n",
        "    \\begin{cases}\n",
        "        \\frac{(1-\\rho)\\rho^i}{1-\\rho^{K+1}} & \\text{if } i \\in \\{0, 1, \\dotsc, K \\} \\\\\n",
        "        0 & \\text{otherwise.}\n",
        "    \\end{cases}\n",
        "$$\n",
        "\n",
        "What does this graph illustrate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Computing the stationary distribution pi\n",
        "rho = lambd / mu\n",
        "\n",
        "pi_mm1k_i = lambda i: 0 if i not in range(0, K+1) else (1-rho)*(rho**i) / (1 - rho**(K+1))\n",
        "\n",
        "lin = np.arange(0, 4)\n",
        "pi_distrib = np.array([pi_mm1k_i(i) for i in lin]) \n",
        "    \n",
        "print(pi_distrib.shape)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "# Displaying the normalized histogram of X_n\n",
        "X_distrib = np.bincount(X.astype(int))\n",
        "\n",
        "plt.stem(X_distrib/niter)\n",
        "\n",
        "# Displaying pi\n",
        "plt.stem(pi_distrib, linefmt=\"green\", markerfmt=\"go\")\n",
        "\n",
        "plt.title(\"Normalized histogram of X_n and stationary distribution pi\")\n",
        "plt.title(\"Normalized histogram of X_n and stationary distribution pi\")\n",
        "plt.legend([\"Normalized histogram of X_n\",\"Stationary distribution pi\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "b) Compute the theoretical average number of customers, and estimate its value using the function developed in 3.a). <!--(see TD3, exercise 3)-->"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "To compute the theoretical average number of customers we use the following formula:\n",
        "$$\n",
        "\\mathbb E_{\\pi}(X_n) = \\sum_{i=0}^{K} i \\lim_{n \\rightarrow \\infty} \\mathbb P(X_n = i) = \\sum_{i=0}^{K} i \\frac{(1-\\rho)\\rho^i}{1-\\rho^{K+1}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Computing the average number of customers and the theoretical value\n",
        "avg_customers = X.mean()\n",
        "theo_value = ((1-rho)/(1-rho**(K+1))) * sum([n*rho**n for n in range(K+1)])\n",
        "\n",
        "# Comparing it to the theoretical value\n",
        "print(f\"Average number of customers for this simulation: {avg_customers}\")\n",
        "print(f\"Theoretical value: {theo_value}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "---\n",
        "## <a name=\"ex2\">Exercise 2: Drawing samples from the Ising model with the Metropolis-Hasings algorithm</a> [(&#8593;)](attachment:./#content)\n",
        "\n",
        "Consider the 2D Ising model covered in Chapter 3, section 3 of the lecture notes, taken over an $N \\times N$ grid for $N = 64$, with $\\beta = 0.6$. <!-- Chapter 3, p.36 -->\n",
        "\n",
        "1\\. Implement a Metropolis-Hastings algorithm to draw samples from the 2D Ising model in the above configuration. Progressively display the evolution of the image as the algorithm evolves. Generate 1000 such variables, starting from a random configuration. Qualitatively comment the content of the last few generated samples, in comparison with the initial state.\n",
        "\n",
        "> *Note*: a) the matlpotlib examples given [here](http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/) can be useful\n",
        ">\n",
        "> b) given the relatively slow evolution from one itearition to another, you may display the current state of the image only once every 20 iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Metropolis-Hastings algorithm applied to the Ising model is as follows:\n",
        "\n",
        "1. Pick a site at random (we use a uniform distribution).\n",
        "2. Flip the value of its spin.\n",
        "3. Compute the energy $\\mathcal H(B')$ of the new state $B'$ and compare it with the current state's ($B$) energy. Energy is obtained with the formula :\n",
        "   $$\n",
        "    \\mathcal H(B) = - \\sum_{(i,j) \\sim (i_1, j_1)} b_{(i,j)} b_{(i_1,j_1)}\n",
        "   $$\n",
        "   Where $(i,j) \\sim (i_1, j_1)$ means that $(i_1, j_1)$ is a neighbour site of $(i,j)$\n",
        "4. Compute the probability to accept the new state, given by: \n",
        "   $$\n",
        "   \\alpha = \\exp(- \\beta(\\mathcal H(B') - \\mathcal H(B)))\n",
        "   $$\n",
        "5. Accept or not this new state.\n",
        "6. Repeat 1-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "# Implementation of the Metropolis-Hastings algorithm\n",
        "\n",
        "def metropolis_hastings(N, beta, N_iter, seed):\n",
        "    \"\"\"Simulates a succession of states for the Ising model using the Metropolis-Hastings algorithm.\n",
        "\n",
        "    Args:\n",
        "        N (int): Size of the grid\n",
        "        beta (float): Parameter of the Ising model.\n",
        "        N_iter (int): Number of iterations\n",
        "        seed (int): Random seed (or random generator).\n",
        "\n",
        "    Returns:\n",
        "        list[np.array]: List of all the states taken during the simulation.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialization\n",
        "    random = np.random.default_rng(seed)\n",
        "    grid = 2*random.integers(2, size=(N,N))-1\n",
        "    states = [grid]\n",
        "    \n",
        "    for k in range(1, N_iter):\n",
        "        # Choose a site uniformly among those that differ only by one spin\n",
        "        (i, j) = random.integers(0, N, size = 2)\n",
        "        \n",
        "        # Flip the value at the site and calculate the energies\n",
        "        candidate = np.copy(states[k-1])\n",
        "        candidate[i,j] *= -1\n",
        "        \n",
        "        current_energy   = compute_energy(states[k-1], i, j)\n",
        "        candidate_energy = compute_energy(candidate, i, j)\n",
        "        \n",
        "        # Compute the probability to accept the candidate state\n",
        "        alpha = np.exp(-beta*(candidate_energy - current_energy))\n",
        "        \n",
        "        # Decide whether to accept it or not\n",
        "        u = random.uniform()\n",
        "        if u < alpha :\n",
        "            next = candidate\n",
        "        else: next = np.copy(states[k-1])\n",
        "        \n",
        "        # Store results\n",
        "        states.append(next)\n",
        "    \n",
        "    return states        \n",
        "        \n",
        "def compute_energy(grid, i, j):\n",
        "    \"\"\"Computes the energy at a site for a given square matrix.\n",
        "\n",
        "    Args:\n",
        "        grid (numpy.array): Square matrix of spins.\n",
        "        i (int): First coordinate of the site.\n",
        "        j (int): Second coordinate of the site.\n",
        "\n",
        "    Returns:\n",
        "        int: Energy at the given site.\n",
        "    \"\"\"\n",
        "    N = grid.shape[0]\n",
        "    site = grid[i,j]\n",
        "    energy = - site * (\n",
        "        (i-1 >= 0) * grid[(i-1)%N, j] +\n",
        "        (i+1 <  N) * grid[(i+1)%N, j] +\n",
        "        (j-1 >= 0) * grid[i, (j-1)%N] +\n",
        "        (j+1 <  N) * grid[i, (j+1)%N]\n",
        "        )\n",
        "    return energy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def animate_states(states, file_name):\n",
        "    \"\"\"Animates the successive states and saves the animation in a .mp4 file.\n",
        "\n",
        "    Args:\n",
        "        states (list[numpy.array]): List of matrices containing the successive states of the system.\n",
        "        file_name (string): Name of the file to save the animation in.\n",
        "    \"\"\"\n",
        "    \n",
        "    states_subsampled = states[0::100]\n",
        "\n",
        "    fig = plt.figure()\n",
        "    im  = plt.imshow(states_subsampled[0],cmap='gray')\n",
        "\n",
        "    def init():\n",
        "        im.set_data(states_subsampled[0])\n",
        "        return [im]\n",
        "\n",
        "    def animate(i):\n",
        "        im.set_array(states_subsampled[i])\n",
        "        return im\n",
        "\n",
        "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                                frames=len(states_subsampled), interval=20, blit=True)\n",
        "    \n",
        "    anim.save(file_name, fps=30, extra_args=['-vcodec', 'libx264'])\n",
        "    HTML(anim.to_html5_video()) # The HTML embed does not seem to work, so we save the animations in .mp4 files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = metropolis_hastings(N=64, beta=0.6, N_iter=10000, seed=rng)\n",
        "animate_states(states, 'beta_6.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that \"clusters\" are being formed in the grid, meaning that particles of identical spin are regrouped. This demonstrates the point of this model, which is that the system favours low-energy states. The energy formula shows that low-energy states are attained when a particle has the same spin as many of its other neighbours."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "2\\. Decrease the value of the parameter $\\beta = 0.1$, and generate 1000 new variables with the algorithm implemented in 1. What is the influence of the parameter $\\beta$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": [
        "states = metropolis_hastings(N=64, beta=0.1, N_iter=10000, seed=rng)\n",
        "animate_states(states, 'beta_1.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With $\\beta = 0.1$, the algorithm does not seem to be able to converge. Indeed, $\\beta$ regulates the probability to accept a new state: if $\\beta$ is low, this probability is also low and the state changes are much more random (going to lesser energy states is less encouraged)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "---\n",
        "## <a name=\"ex3\">Exercise 3: Simulated annealing for the *traveling salesman* problem</a> [(&#8593;)](attachment:./#content)\n",
        "\n",
        "This exercise will be focused on the implementation of a basic simulated annealing algorithm to minimize a function $f : E \\subset \\mathbb{N} \\rightarrow \\mathbb{R}$, where $E$ is finite. An application to the *traveling salesman* problem will then be considered to test the algorithm implementation. \n",
        "\n",
        "In general, a simulated annealing algorithm can be described as follows.\n",
        "\n",
        "---\n",
        "**Simulated annealing**\n",
        "\n",
        "Set $x_0 \\in E$, $T_0  > 0$. \n",
        "\n",
        "$n \\leftarrow 0$\n",
        "\n",
        "While $(n \\leq N)$ and $(T_n > T_{\\min})$\n",
        "\n",
        "  1. Draw a point $y \\sim Q(x_n, \\cdot)$ in the neighborhood of $x_n$, and $u \\sim \\mathscr{U}([0,1])$ (where $\\mathscr{U}$ is the uniform distribution)\n",
        "  \n",
        "  2. Compute the acceptance probability: \n",
        "  \n",
        "$$\n",
        "    p(f(x_n), f(y), T_n) = \n",
        "    \\begin{cases}\n",
        "        1 & \\text{if } f(y) < f(x_n) \\\\\n",
        "        \\text{e}^{-(f(y) - f(x_n))/T_n} & \\text{otherwise.}\n",
        "    \\end{cases}\n",
        "$$\n",
        "  \n",
        "  3. Set $x_{n+1} = \\begin{cases}\n",
        "       y & \\text{if } u \\leq p(f(x_n), f(y), T_n) \\\\\n",
        "       x_n & \\text{otherwise.}\n",
        "       \\end{cases}$\n",
        "  4. Set $T_{n+1} = \\frac{T_0}{\\log(n+2)}$\n",
        "  5. $n \\leftarrow n+1$\n",
        "\n",
        "Return $x_N$, $\\bigl( f(x_n) \\bigr)_{1 \\leq n \\leq N}$\n",
        "\n",
        "> *Note*: in practice, the transition kernel $Q$, the neighborhood of the current point $x_n$ needs to be defined by the user, depending on the problem of interest. The definition of the other elements will be specified later for the *traveling salesman* problem.\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "1\\. Implement a generic `simulated_annealing` function to be run for a maximum of $N$ iterations.\n",
        "\n",
        "> *Note*: you can for instance create an object gathering several abstract methods to be instanciated (e.g., `draw_neighbour`, `acceptance_probability`, ...). Using functions and lambda functions is another possibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "The algorithm implemented in 1. will be applied to the *traveling salesman* problem, briefly described in the following lines.\n",
        "\n",
        "---\n",
        "**The Traveling Salesman problem**\n",
        "\n",
        "A salesman must find the shortest route going only once through $K$ cities, represented by the points $C_1, \\dotsc, C_K$ in $\\mathbb{R}^2$. In this case, the set of all possible routes $E$ contains $K!$ elements, which excludes an exhaustive search as $K$ increases (*e.g.*, for $K \\geq 10$). For this application, the problem thus consists in finding a route, i.e., a permutation $\\sigma$ in the symmetric group $\\Sigma_K$, minimizing the function\n",
        "\n",
        "\\begin{equation}\n",
        "    \\sigma = \\bigl( \\sigma(1), \\dotsc , \\sigma(K) \\bigr) \\mapsto f(x) = \\sum_{i = 1}^{K} \\text{dist} (C_{\\sigma(i)}, C_{\\sigma(i+1)})\n",
        "\\end{equation}\n",
        "\n",
        "with the convention $\\sigma(K+1) = \\sigma(1)$. In this case, simulated annealing randomly explores $\\Sigma_K$ from one possible route to another located in its vicinity (which needs to be defined). \n",
        "\n",
        "In the following, the route $\\tilde{\\sigma} = \\bigl( \\tilde{\\sigma}(1), \\dotsc, \\tilde{\\sigma}(K) \\bigr)$ will be said to be a neighbour of $\\sigma = \\bigl( \\sigma(1), \\dotsc, \\sigma(K) \\bigr)$ if there exists $1 \\leq i < k \\leq K $ such that:\n",
        "\n",
        "\\begin{equation}\n",
        "   \\bigl( \\tilde{\\sigma}(1), \\dotsc ,\\tilde{\\sigma}(K) \\bigr) = \\bigl( \\sigma(1), \\dotsc, \\sigma(i−1), \\sigma(k), \\sigma(k−1), \\dotsc, \\sigma(i+1), \\sigma(i), \\sigma(k+1), \\dotsc, \\sigma(K) \\bigr). \n",
        "\\end{equation}\n",
        "\n",
        "For instance, for $K = 8$, the permutations $(1,2,3,4,8,7,6,5)$ and $(1,2,7,8,4,3,6,5)$ are neighbours (with $i = 3$, $k = 6$).\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "2\\. Fully instantiate the simulated annealing algorithm for the traveling salesman problem. Take the $\\ell_2$ norm for $\\text{dist}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "source": [
        "3\\. Test your algorithm for $K = 50$ randomly located cities (i.e., generate the values of $(C_k)_{1 \\leq k \\leq K}$ randomly). Display both the evolution of the cost function with the iterations and the final route. Empirically tune the value $T_0$ to improve the result of the algorithm.\n",
        "\n",
        "> *Notes*:\n",
        ">\n",
        "> a) for reproducibility, set the random seed of the random number generator to a specific value, *e.g.*, 0;\n",
        ">\n",
        "> b) to generate an initial path $x_0$, you can for instance randomly select a starting city $k$, and define the next city sequentially by taking its *nearest neighbour*;\n",
        ">\n",
        "> c) to display the trajectory, you can use `matplotlib.pyplot.arrow` to display an arrow between two consecutive points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "34ff3397c474938b265d2f4b45024e5465249fab18e07736c9a068b37b408800"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('python-all': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
