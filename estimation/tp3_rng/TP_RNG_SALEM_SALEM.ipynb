{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elève 1 : Emilie Salem\n",
    "## Elève 2 : Hadrien Salem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform, cauchy, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse de la fonction de répartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des fonctions nécessaires\n",
    "lambda_exp = 2\n",
    "f = lambda x : lambda_exp*np.exp(-lambda_exp*x)\n",
    "F = lambda x : 1 - np.exp(-lambda_exp*x)\n",
    "F_inv = lambda u : -np.log(1-u) / lambda_exp\n",
    "\n",
    "# Définition de la fonction de génération de nombres aléatoires suivant la loi exponentielle\n",
    "def rng_exp(nb_echantillons) :\n",
    "    echantillons_unif = uniform.rvs(loc = 0, scale = 1, size = nb_echantillons)\n",
    "    echantillons_exp = F_inv(echantillons_unif)\n",
    "    return echantillons_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage pour la génération de 10000 points\n",
    "samples = rng_exp(10000)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(samples, 'o')\n",
    "plt.title('10000 échantillons générés à partir de la loi exponentielle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité exponentielle et des points générées\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(0, 4, 10000)\n",
    "plt.plot(t, f(t), 'r')\n",
    "plt.title('Densité de probabilité exponentielle et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "On constate qu'avec cette méthode, on obtient un bon échantillonnage de la loi exponentielle. Cependant, la principale limitation de cette méthode est qu'il faut être capable de calculer l'inverse généralisée d'une fonction, ce qui n'est pas toujours trivial. En l'occurrence, nous étions dans un cas où l'inverse se calcule simplement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode Accept-Reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des fonctions et variables nécessaires\n",
    "g = lambda x : 1 / (np.pi*(1 + x**2))\n",
    "M = 5\n",
    "\n",
    "# Définition de la fonction de génération de nombres aléatoires suivant la loi exponentielle\n",
    "def accept_reject(nb_echantillons, mu_norm) :\n",
    "    samples = []\n",
    "    for i in range(nb_echantillons):\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        x = cauchy.rvs(loc = 0, scale = 1, size = 1)\n",
    "        while(norm.pdf(x=x, loc=mu_norm, scale=1) / (M * cauchy.pdf(x=x, loc=0, scale=1))) < u :\n",
    "            u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "            x = cauchy.rvs(loc = 0, scale = 1, size = 1)\n",
    "        samples.append(x)\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage pour la génération de 1000 points\n",
    "samples_cr = accept_reject(10000, 0)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(samples_cr, 'o')\n",
    "plt.title('10000 échantillons générés à partir de la loi centrée réduite')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité centrée réduite et des points générées\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_cr, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-4, 4, 10000)\n",
    "plt.plot(t, norm.pdf(x=t, loc=0, scale=1), 'r')\n",
    "plt.title('Densité de probabilité centrée réduite et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Échantillonnage de la loi normale (5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_cr_5 = accept_reject(10000, 5)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_cr_5, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(0, 10, 10000)\n",
    "plt.plot(t, norm.pdf(x=t, loc=5, scale=1), 'r')\n",
    "plt.title('Densité de probabilité normale et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "On observe que la méthode accept-reject donne de bons résultats pour échantillonner selon une loi normale centrée réduite. En revanche, pour une loi normale centrée en 5 on obtient des résultats beaucoup moins satisfaisants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loi de Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.7\n",
    "\n",
    "# Définition de la fonction de génération de nombres aléatoires suivant la loi de Bernoulli\n",
    "def rng_bernoulli(nb_echantillons) :\n",
    "    echantillons_bernoulli = []\n",
    "    for i in range(nb_echantillons):\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        if u < p :\n",
    "            echantillons_bernoulli.append(0)\n",
    "        else :\n",
    "            echantillons_bernoulli.append(1)\n",
    "    return np.array(echantillons_bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage pour la génération de 10000 points\n",
    "samples_br = rng_bernoulli(10000)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(samples_br, 'o')\n",
    "plt.title('10000 échantillons générés à partir de la loi de Bernoulli')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(samples_br).count(0) / samples_br.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Empiriquement, on retrouve bien la probabilité de succès désirée p = 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes de Monte Carlo Markov Chain (MCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings avec loi de proposition indépendante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unif[-1, 1] et burn-in de 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densité de la loi normale centrée réduite\n",
    "f = lambda x : np.exp(-(x**2)/2) / np.sqrt(2*np.pi)\n",
    "# Densité de la loi uniforme sur [-1, 1]\n",
    "def q(x) :\n",
    "    if(x >= -1) and (x <= 1) : return 1/2\n",
    "    else : return 0\n",
    "\n",
    "def MH_ind(nb_echantillons, temps_chauffe) :\n",
    "    echantillons_MH_ind= []\n",
    "    x_t = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "    y_t = uniform.rvs(loc = -1, scale = 2, size = 1)\n",
    "    for t in range(nb_echantillons + temps_chauffe) :\n",
    "        rho = min(1, f(y_t)*q(x_t)/(f(x_t)*q(y_t)))\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        if u < rho :\n",
    "            x_t = y_t\n",
    "        if(t > temps_chauffe) :\n",
    "            echantillons_MH_ind.append(x_t)\n",
    "        y_t = uniform.rvs(loc = -1, scale = 2, size = 1)\n",
    "    return np.array(echantillons_MH_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_MH_ind = MH_ind(20000, 500)\n",
    "\n",
    "# Affichage sur la même figure de la densité de probabilité centrée réduite et des points générées\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_ind, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-4, 4, 20000)\n",
    "plt.plot(t, f(t), 'r')\n",
    "plt.title('Densité de probabilité centrée réduite et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "On observe que toutes les valeurs échantillonnées sont comprises entre -1 et 1 : c'est dû à la loi de proposition qui est uniforme sur [-1,1]. Or, en suivant une loi normale centrée réduite, la probabilité de tirer un nombre hors de [-1,1] n'est pas négligeable : la probabilité de $\\mathbb{R} \\backslash [-1,1]$ est supérieure à 30%. On en déduit que la loi de proposition n'est pas adaptée. Dans la suite, on utilise donc une loi uniforme sur un intervalle étendu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unif[-10, 10] et burn-in de 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densité de la loi normale centrée réduite\n",
    "f = lambda x : np.exp(-(x**2)/2) / np.sqrt(2*np.pi)\n",
    "# Densité de la loi uniforme sur [-10, 10]\n",
    "def q(x) :\n",
    "    if(x >= -10) and (x <= 10) : return 1/20\n",
    "    else : return 0\n",
    "\n",
    "def MH_ind(nb_echantillons, temps_chauffe) :\n",
    "    echantillons_MH_ind= []\n",
    "    x_t = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "    y_t = uniform.rvs(loc = -10, scale = 20, size = 1)\n",
    "    for t in range(nb_echantillons + temps_chauffe) :\n",
    "        rho = min(1, f(y_t)*q(x_t)/(f(x_t)*q(y_t)))\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        if u < rho :\n",
    "            x_t = y_t\n",
    "        if(t > temps_chauffe) :\n",
    "            echantillons_MH_ind.append(x_t)\n",
    "        y_t = uniform.rvs(loc = -10, scale = 20, size = 1)\n",
    "    return np.array(echantillons_MH_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité centrée réduite et des points générées\n",
    "samples_MH_ind = MH_ind(20000, 1000)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_ind, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-4, 4, 20000)\n",
    "plt.plot(t, f(t), 'r')\n",
    "plt.title('Densité de probabilité centrée réduite et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Comme on s'y attendait, l'utilisation d'une loi uniforme sur [-10,10] donne de meilleurs résultats, la probabilité de $\\mathbb{R} \\backslash [-10,10]$ étant négligeable.\n",
    "\n",
    "On va maintenant s'intéresser à l'influence du burning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité centrée réduite et des points générées\n",
    "samples_MH_ind = MH_ind(20000, 100)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_ind, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-4, 4, 20000)\n",
    "plt.plot(t, f(t), 'r')\n",
    "plt.title('Densité de probabilité centrée réduite et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Dans l'expérimentation ci-dessus, on a réduit le temps de chauffe à 100 en gardant 20000 tirages. On s'attendait à ce que les résultats soient moins bons parce que l'algorithme n'aurait pas eu le temps de converger. Cependant, l'échantillonnage obtenu semble équivalent en qualité à celui obtenu précédemment. On fait la conjecture qu'en raison du nombre d'échantillons élevé, l'influence du temps de chauffe est réduite. Dans l'exemple suivant, on décide donc de diminuer le nombre d'échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité centrée réduite et des points générées\n",
    "samples_MH_ind = MH_ind(1000, 500)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_ind, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-4, 4, 20000)\n",
    "plt.plot(t, f(t), 'r')\n",
    "plt.title('Densité de probabilité centrée réduite et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Comme on s'y attendait, l'échantillonnage semble beaucoup moins bon avec un nombre d'échantillons réduit et un temps de chauffe plus faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings avec une loi à deux modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la loi à deux modes\n",
    "def f(x, p, mu1, mu2, a1, a2):\n",
    "    return p / (2*a1) * np.exp(-abs((x-mu1)/a1)) + (1-p) / (2*a2) * np.exp(-abs((x-mu2)/a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "t = np.linspace(-20, 20, 20000)\n",
    "plt.plot(t, f(t, 0.3, 10, -5, 1, 2), 'r')\n",
    "plt.title('Densité de probabilité de la fonction à deux modes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = norm\n",
    "\n",
    "def MH_modes(nb_echantillons, temps_chauffe) :\n",
    "    echantillons_MH_modes= []\n",
    "    x_t = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "    y_t = norm.rvs(loc = 0, scale = 20, size = 1)\n",
    "    for t in range(nb_echantillons + temps_chauffe) :\n",
    "        rho = min(1, f(y_t, 0.3, 10, -5, 1, 2)*q.pdf(x_t, loc = 0, scale=20)\n",
    "                  /(f(x_t, 0.3, 10, -5, 1, 2)*q.pdf(y_t, loc = 0, scale=20)))\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        if u < rho :\n",
    "            x_t = y_t\n",
    "        if(t > temps_chauffe) :\n",
    "            echantillons_MH_modes.append(x_t)\n",
    "        y_t = norm.rvs(loc = 0, scale = 20, size = 1)\n",
    "    return np.array(echantillons_MH_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage pour la génération de 20000 points\n",
    "samples_MH_modes = MH_modes(20000, 500)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(samples_MH_modes, 'o')\n",
    "plt.title(\"20000 échantillons générés à partir de l'algorithme Metropolis-Hastings pour la loi à 2 modes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité et des points générées\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_modes, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-20, 20, 20000)\n",
    "plt.plot(t, f(t, 0.3, 10, -5, 1, 2), 'r')\n",
    "plt.title('Densité de probabilité et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Nous avons choisi d'utiliser la loi normale de moyenne 0 et d'écart-type 20 afin de couvrir la plage de valeurs la plus probable pour la fonction de densité à deux modes. Au vu de l'échantillonnage, ce choix semble pertinent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echantillonnage de Monte Carlo parfait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = norm\n",
    "q = uniform\n",
    "\n",
    "def MH_MC(nb_echantillons, temps_chauffe) :\n",
    "    echantillons_MH_MC= []\n",
    "    x_t = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "    y_t = uniform.rvs(loc = -10, scale = 20, size = 1)\n",
    "    for t in range(nb_echantillons + temps_chauffe) :\n",
    "        rho = min(1, f.pdf(y_t, loc = 5, scale = 2)*q.pdf(x_t, loc = -10, scale = 20)\n",
    "                  /(f.pdf(x_t, loc = 5, scale = 2)*q.pdf(y_t, loc = -10, scale = 20)))\n",
    "        u = uniform.rvs(loc = 0, scale = 1, size = 1)\n",
    "        if u < rho :\n",
    "            x_t = y_t\n",
    "        if(t > temps_chauffe) :\n",
    "            echantillons_MH_MC.append(x_t)\n",
    "        y_t = uniform.rvs(loc = -10, scale = 20, size = 1)\n",
    "    return np.array(echantillons_MH_MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage pour la génération de 20000 points\n",
    "samples_MH_MC = MH_MC(20000, 500)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(samples_MH_MC, 'o')\n",
    "plt.title(\"20000 échantillons générés à partir de l'algorithme Metropolis-Hastings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sur la même figure de la densité de probabilité et des points générées\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(samples_MH_MC, density=True, bins=100) # density=true normalise l'histogramme\n",
    "t = np.linspace(-20, 20, 20000)\n",
    "plt.plot(t, f.pdf(t, loc = 5, scale = 2), 'r')\n",
    "plt.title('Densité de probabilité et histogramme des points générés')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_with_MC(samples):\n",
    "    nb_samples = np.size(samples)\n",
    "    return 1/nb_samples * np.sum(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_with_MC(MH_MC(100, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec 100 particules pour 100 calculs de moyenne\n",
    "On a réduit le nombre de calculs par rapport à ce qui est demandé dans l'énoncé en raison du temps de calcul très important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vm = [mean_with_MC(MH_MC(100, 500)) for _ in range(100)]\n",
    "plt.plot(Vm)\n",
    "np.std(Vm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "On observe qu'avec 100 particules l'échantillonnage de Monte-Carlo permet bien d'estimer la moyenne (qui vaut 5 ici) mais avec une erreur de l'ordre de 8% (on obtient empiriquement un écart type d'environ 0.39 autour de la moyenne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec 1000 particules pour 100 calculs de moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vm = [mean_with_MC(MH_MC(1000, 500)) for _ in range(100)]\n",
    "plt.plot(Vm)\n",
    "np.std(Vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "Comme annoncé théoriquement, la variance de l'estimation diminue lorsqu'on augmente le nombre de particules : avec 1000 particules, l'écart-type est d'environ 0.12 < 0.39."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec 10000 particules pour 100 calculs de moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec 10000 particules pour 100 calculs de moyenne\n",
    "# Vm = [mean_with_MC(MH_MC(10000, 500)) for _ in range(100)]\n",
    "# plt.plot(Vm)\n",
    "\n",
    "# On n'exécute pas cette cellule en raison du temps de calcul, mais on s'attend à une estimation encore plus précise de la moyenne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode de Box-Muller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_muller(nb_samples):\n",
    "    samples_z1 = []\n",
    "    samples_z2 = []\n",
    "    for _ in range(nb_samples):\n",
    "        u1 = uniform.rvs(loc=0, scale=1, size=1)\n",
    "        u2 = uniform.rvs(loc=0, scale=1, size=1)\n",
    "\n",
    "        R = -2*np.log(u1)\n",
    "        V = 2 * np.pi * u2\n",
    "\n",
    "        z1, z2 = np.sqrt(R)*np.cos(V), np.sqrt(R)*np.sin(V)\n",
    "        samples_z1.append(z1)    \n",
    "        samples_z2.append(z2)    \n",
    "    return np.array(samples_z1), np.array(samples_z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_z1, samples_z2 = box_muller(10000)\n",
    "t = np.linspace(-4, 4, 10000)\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(samples_z1, density=True, bins=100) # density=true normalise l'histogramme\n",
    "plt.plot(t, norm.pdf(x=t, loc=0, scale=1), 'r')\n",
    "plt.title('Échantillonnage pour z1')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(samples_z2, density=True, bins=100) # density=true normalise l'histogramme\n",
    "plt.plot(t, norm.pdf(x=t, loc=0, scale=1), 'r')\n",
    "plt.title('Échantillonnage pour z2')\n",
    "plt.legend(['Densité réelle', 'Densité estimée'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "On constate que les deux composantes $z_1$, $z_2$ ont bien été échantillonnées suivant la loi normale centrée réduite. Ainsi, le vecteur $Z = (z_1, z_2)$ suit bien une loi normale bivariée réduite."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ced0699d32d8e6de29d5369718307d99fab179af6891fd9441585b0b827fbd5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('sdia-python': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
