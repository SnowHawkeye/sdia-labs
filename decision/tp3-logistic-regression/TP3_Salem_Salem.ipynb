{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TP3 : Logistic regression\n",
        "\n",
        "The purpose of this tutorial is to implement and use the Logistic Regression for binary classification. We will apply this\n",
        "method to the problem of handwritten characters to learn how to\n",
        "distinguish two numbers (here 5 and 6)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pylab import *\n",
        "from numpy import linalg as la \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import sklearn as skl\n",
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Logistic regression, IRLS algorithm."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preliminary question: the algorithm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Have a look at the function `regression_logistique.m` and locate the main steps of the algorithm you have been taught (see course).\n",
        "You can comment the code in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def regression_logistique(X,t,Nitermax=20,eps_conv=1e-3):\n",
        "    '''Entrees :\n",
        "    X = [ones(N_train,1) x_train];\n",
        "    t = class_train \n",
        "    Nitermax = nombre maximale d'itérations (20 par défaut)\n",
        "    eps_conv = critère de convergence sur norm(w-w_old)/norm(w) ; \n",
        "    eps_conv=1e-3 par défaut\n",
        "    \n",
        "    Sorties : \n",
        "    w : vecteur des coefficients de régression logistique\n",
        "    Niter : nombre d'itérations utilisées effectivement\n",
        "   \n",
        "   Fonction de régression logistique pour la classification binaire.\n",
        "   \n",
        "   Utilisation :\n",
        "       Nitermax = 50\n",
        "       eps_conv = 1e-4\n",
        "       [w,Niter] = regression_logistique(X,t,Nitermax,eps_conv)\n",
        "    '''\n",
        "    N_train = X.shape[0]\n",
        "\n",
        "    #initialisation : 1 pas de l'algorithme IRLS\n",
        "    w = np.zeros((X.shape[1],)) # w initialisé comme vecteur nul de dimension le nombre d'attributs\n",
        "    w_old = w \n",
        "    y = 1/2*np.ones((N_train,)) # on initialise l'activation (\"w.x\") à 0, y = sgm(wx) vaut alors 0.5\n",
        "    R = np.diag(y*(1-y))   # diag(y_n(1-y_n))\n",
        "    z = X.dot(w_old)-la.inv(R).dot(y-t) # initialisation de z (old)\n",
        "    w = la.inv(X.T.dot(R).dot(X)).dot(X.T).dot(R).dot(z) # calcul de w pour la première étape avec les valeurs initialisées\n",
        "\n",
        "    # boucle appliquant l'algorithme de Newton-Raphson\n",
        "    Niter = 1 # on a déjà fait \"l'itération 1\"\n",
        "    while  (la.norm(w-w_old)/la.norm(w)>eps_conv) & (Niter<Nitermax) : # condition d'arrêt: soit w et w_old sont suffisamment proches, soit on atteint un nombre maximum d'itérations\n",
        "        Niter = Niter+1\n",
        "        y = 1/(1+np.exp(-X.dot(w))) # on calcule y avec la fonction sigma\n",
        "        R = np.diag(y*(1-y)) # par définition de R\n",
        "        # on calcule ensuite z et w avec les formules données par la méthode de Newton-Raphson\n",
        "        w_old = w \n",
        "        z = X.dot(w_old)-la.inv(R).dot(y-t)\n",
        "        w = la.inv(X.T.dot(R).dot(X)).dot(X.T).dot(R).dot(z)\n",
        "         \n",
        "    return w, Niter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading & preparing synthetic data\n",
        "\n",
        "Load the training and test data sets `synth_train.txt`\n",
        "and `synth_test.txt`. The targets t belong to {1,2} and the features  \n",
        "x belong to R^2. \n",
        "\n",
        "We have 100 training samples and 200 test samples\n",
        "\n",
        "* the 1st column contains the label of each sample, \n",
        "* columns 2 and 3 contain the coordinate of each point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training set\n",
        "synth_train = np.loadtxt('synth_train.txt') \n",
        "class_train = synth_train[:,0]\n",
        "class_train_1 = np.where(synth_train[:,0]==1)[0]\n",
        "class_train_2 = np.where(synth_train[:,0]==2)[0]\n",
        "x_train = synth_train[:,1:]\n",
        "N_train = np.size(x_train,axis=0)\n",
        "\n",
        "# Test set\n",
        "synth_test = np.loadtxt('synth_test.txt')\n",
        "class_test = synth_test[:,0]\n",
        "class_test_1 = np.where(synth_test[:,0]==1)[0]\n",
        "class_test_2 = np.where(synth_test[:,0]==2)[0]\n",
        "x_test = synth_test[:,1:]\n",
        "N_test = np.size(x_test,axis=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing features for logistic regression (binary classification)\n",
        "First, we prepare the feature matrix and the target vector associated to \n",
        "the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.hstack((np.ones((N_train,1)),x_train))\n",
        "t = 2-class_train   # 0 if class=2, 1 if class=1\n",
        "\n",
        "X_test = np.hstack((np.ones((N_test,1)),x_test))\n",
        "t_test = 2-class_test   # 0 if class=2, 1 if class=1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1 : the logistic function of decision\n",
        "\n",
        "1. Use the function `regression_logistique.m` to estimate the logistic\n",
        "regression vector `w`. *Indication : use `Nitermax = 50;\n",
        "eps_conv=1e-3;`.*\n",
        "2. Compute the decision function $f(x) = argmax_k P(C_k|x)$ on the test set\n",
        "to get the classification results. Recall that $y_n=\\sigma(w^T x)$ (logistic function)\n",
        "and that *using vectors* you may directly write $y=\\sigma(Xw)$, with the\n",
        "column of ones in X.\n",
        "3. Display the results by plotting the points from both the training set\n",
        "and the test set.\n",
        "4. Write the equation which defines the decision boundary.\n",
        "5. Artificially add a few points to the training set far from the decision boundary to check the robustness of logistic regression to outliers. Check the behaviour of LDA for comparison in this case and comment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q1: Estimate the logistic regression vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w, Niter = regression_logistique(X, t, Nitermax=50)\n",
        "print(f\"The regression vector is {w} and was found in {Niter} iterations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q2: Compute the decision function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigma(a): return 1/(1+np.exp(-a)) # sigmoid function\n",
        "\n",
        "class LogisticRegression():\n",
        "    \n",
        "    def __init__(self, train_data, train_target, threshold = 0.5, Nitermax = 50, eps_conv = 1e-3):\n",
        "        self.train_data = train_data\n",
        "        self.train_target = train_target\n",
        "        self.threshold = threshold\n",
        "        self.Nitermax = Nitermax\n",
        "        self.eps_conv = eps_conv\n",
        "        self.coefs, self.Niter = self.__get_coeffs()\n",
        "        \n",
        "    def __get_coeffs(self):\n",
        "        return regression_logistique(self.train_data, self.train_target, self.Nitermax, self.eps_conv)\n",
        "        \n",
        "    def predict(self, test_data):\n",
        "        pred = sigma(test_data.dot(self.coefs))\n",
        "        return np.where(pred >= self.threshold, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logReg = LogisticRegression(X, t)\n",
        "logReg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q3: Display results\n",
        "\n",
        "With the goal to use cross-validation and compare with LDA later on, we create a utility class that will help us display data and predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BinaryPointsClassification():\n",
        "    \"\"\"Utility class to help with displaying prediction results and error rates.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, test_data, test_target, f_predict):\n",
        "    \n",
        "        self.test_data = test_data\n",
        "        self.test_target = test_target\n",
        "        self.f_predict = f_predict\n",
        "        \n",
        "        self.prediction = self.f_predict(test_data)\n",
        "        self.errors, self.error_rate = self.__errors()\n",
        "        \n",
        "        self.confusion_matrix = skl.metrics.confusion_matrix(self.test_target, self.prediction)\n",
        "        \n",
        "        \n",
        "    def __errors(self):\n",
        "        \"\"\"Returns the points that were classified wrongly and the error rate.\n",
        "        \"\"\"\n",
        "        \n",
        "        is_wrong_prediction = np.logical_or(np.logical_and(self.prediction[:] == 1, self.test_target[:] == 0), np.logical_and(self.prediction[:] == 0, self.test_target[:] == 1))\n",
        "        errors = self.test_data[is_wrong_prediction, :][:,1:]\n",
        "        error_rate = len(errors) / len(self.test_data)\n",
        "        \n",
        "        return errors, error_rate\n",
        "\n",
        "    def predicted_points_figure(self, title=\"\"):\n",
        "        \"\"\"Given a set of points and binary predictions (0-1), returns a graph showing the classification, crossing out the mistakes.\n",
        "        \"\"\"\n",
        "        \n",
        "        x_predicted_0 = self.test_data[self.prediction[:] == 0, :][:,1:]\n",
        "        x_predicted_1 = self.test_data[self.prediction[:] == 1, :][:,1:]\n",
        "\n",
        "        plt.scatter(x_predicted_0[:,0], x_predicted_0[:,1], c='r')\n",
        "        plt.scatter(x_predicted_1[:,0], x_predicted_1[:,1], c='g')\n",
        "        plt.scatter(self.errors[:,0], self.errors[:,1], c='b', marker = 'x')\n",
        "        plt.title(title + \"\\n(mistakes are crossed out in blue)\")\n",
        "        \n",
        "        \n",
        "    def decision_regions_figure(self, x1_bounds, x2_bounds, resolution=1000):\n",
        "        \"\"\"Displays the decision regions for a given resolution (number of points along each axis).\n",
        "        \"\"\"\n",
        "\n",
        "        x1 = np.linspace(x1_bounds[0], x1_bounds[1], resolution) \n",
        "        x2 = np.linspace(x2_bounds[0], x2_bounds[1], resolution) \n",
        "        X1, X2 = meshgrid(x1,x2)\n",
        "        \n",
        "        X = np.stack((np.ones(resolution**2), np.ravel(X1), np.ravel(X2))).T\n",
        "        Z = self.f_predict(X).reshape(X1.shape)\n",
        "\n",
        "        plt.contourf(X1, X2, Z, colors=['r', 'g', 'b', \"y\", 'purple'], alpha = 0.3) # extra colors are necessary otherwise everything is green and the boundary is red         \n",
        "        \n",
        "        \n",
        "    def confusion_matrix_heatmap(self):\n",
        "        \"\"\"Displays the heatmap corresponding to the confusion matrix.\"\"\"\n",
        "        sns.heatmap(self.confusion_matrix, annot=True, fmt='d', cmap=plt.cm.Purples, xticklabels=['red', 'green'], yticklabels=['red', 'green'])      \n",
        "         \n",
        "        \n",
        "    def display_prediction(self, x1_bounds, x2_bounds, resolution = 1000, figsize=(20,5) , title = \"Classification\"):\n",
        "        \"\"\"Convenient all-in-one display function. Displays the decision regions, the classified points (with mistakes) and the confusion matrix heatmap.\n",
        "        \"\"\"\n",
        "        \n",
        "        plt.figure(figsize=figsize)\n",
        "\n",
        "        plt.subplot(121)\n",
        "        self.predicted_points_figure(title)\n",
        "        self.decision_regions_figure(x1_bounds, x2_bounds, resolution)\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plt.title(\"Confusion matrix\\nThe X axis corresponds to predicted labels\")\n",
        "        self.confusion_matrix_heatmap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1_bounds=(-2.5, 1.5)\n",
        "x2_bounds=(-1, 5)\n",
        "figsize=(20,5)\n",
        "\n",
        "logReg = LogisticRegression(X, t)\n",
        "\n",
        "# Results for the test set\n",
        "classification_test = BinaryPointsClassification(X_test, t_test, logReg.predict)\n",
        "classification_test.display_prediction(x1_bounds, x2_bounds, resolution = 1000, title = f\"Test set classification (error rate: {classification_test.error_rate*100}%)\")\n",
        "\n",
        "# Results for the training set\n",
        "classification_train = BinaryPointsClassification(X, t, logReg.predict)\n",
        "classification_train.display_prediction(x1_bounds, x2_bounds, resolution = 1000, figsize = figsize, title = f\"Train set classification (error rate: {classification_train.error_rate*100}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the classifier makes a lot more mistakes on class 1 (green points) than class 0 (red points) on the test set. That's because there were not enough green points in the training set to be able to learn their repartition properly : only 31% of points were of class 1 vs. 69% of class 0, there is a clear imbalance that causes overfitting on red points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q4: Equation of the decision boundary\n",
        "\n",
        "The decision boundary corresponds to the $(x1,x2)$ couples such that $\\sigma(w^T x) = 0.5$. In other words:  $w_0 + w_1 x_1 + w_2 x_2 = 0 $.\n",
        "\n",
        "\n",
        "More generally, for a threshold $\\tau$, we need $\\sigma(w^T x) = \\tau$, hence $w_0 + w_1 x_1 + w_2 x_2 = logit(\\tau)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q5: Add a few points away from the decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb_points = 10\n",
        "outliers = np.stack([np.ones(nb_points), np.linspace(3,4,nb_points), np.linspace(-1,0,nb_points)]).T # generate 10 points far from the decision boundary\n",
        "\n",
        "X_outliers = np.vstack([X, outliers])\n",
        "t_outliers = np.hstack([t, np.zeros(nb_points)]) # all added points are in class 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training the LDA model\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_outliers, t_outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying results\n",
        "\n",
        "x1_bounds = (-2.5, 4.5)\n",
        "x2_bounds=(-1, 5)\n",
        "\n",
        "classification_outliers = BinaryPointsClassification(X_test, t_test, logReg.predict)\n",
        "classification_outliers_lda = BinaryPointsClassification(X_test, t_test, lda.predict)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.scatter(outliers[:,1], outliers[:,2], c='orange')\n",
        "classification_outliers_lda.decision_regions_figure(x1_bounds, x2_bounds)\n",
        "classification_outliers_lda.predicted_points_figure(title=f\"LDA (error rate: {classification_outliers_lda.error_rate*100}%)\")\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.scatter(outliers[:,1], outliers[:,2], c='orange')\n",
        "classification_outliers.decision_regions_figure(x1_bounds, x2_bounds)\n",
        "classification_outliers.predicted_points_figure(title=f\"Logistic regression (error rate: {classification_outliers.error_rate*100}%)\")\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.title(\"Confusion matrix for LDA\\nThe X axis corresponds to predicted labels\")\n",
        "classification_outliers_lda.confusion_matrix_heatmap()\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.title(\"Confusion matrix for Logistic regression\\nThe X axis corresponds to predicted labels\")\n",
        "classification_outliers.confusion_matrix_heatmap()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, we observe that LDA is way more sensitive to outliers than logistic regression: the boundary decision starts leaning towards them, causing many mistakes on green points (class 1). However, the error rate doesn't change for logistic regression: this shows the robustness of this method over LDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extra: Cross-validation\n",
        "\n",
        "In order to better estimate the error rate and find an optimal threshold, we realize a cross validation. We will test 50 values between 0.4 and 0.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need to make an object that sklearn can use\n",
        "\n",
        "def sigma(a): return 1/(1+np.exp(-a)) # sigmoid function\n",
        "\n",
        "class LogisticRegressionCV():\n",
        "    \n",
        "    def __init__(self, threshold = 0.5, Nitermax = 50, eps_conv = 1e-3):\n",
        "        self.threshold = threshold\n",
        "        self.Nitermax = Nitermax\n",
        "        self.eps_conv = eps_conv\n",
        "    \n",
        "    def fit(self, train_data, train_target):\n",
        "        self.train_data = train_data\n",
        "        self.train_target = train_target\n",
        "        self.coefs, self.Niter = self.__get_coeffs()\n",
        "        return self\n",
        "        \n",
        "    def __get_coeffs(self):\n",
        "        return regression_logistique(self.train_data, self.train_target, self.Nitermax, self.eps_conv)\n",
        "    \n",
        "    def get_params(self, deep):\n",
        "        return {'threshold' : self.threshold}\n",
        "        \n",
        "    def predict(self, test_data):\n",
        "        pred = sigma(test_data.dot(self.coefs))\n",
        "        return np.where(pred >= self.threshold, 1, 0)\n",
        "    \n",
        "      \n",
        "# Scorer function that will be used for cross-validation (= error rate)\n",
        "\n",
        "def score_func(y, y_pred, **kwargs):\n",
        "    N = len(y)\n",
        "    error = sum(abs(y_pred-y))/N\n",
        "    return error\n",
        "    \n",
        "scorer = skl.metrics.make_scorer(score_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We regroup all data into two lists that will be split during cross-validation. We do not shuffle them because we expect sklearn to do it.\n",
        "\n",
        "X_all = np.vstack([X, X_test])\n",
        "t_all = np.vstack([t.reshape(len(t), 1), t_test.reshape(len(t_test), 1)])\n",
        "t_all = t_all.reshape(len(t_all),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sklearn cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "folds = 10\n",
        "first_threshold, last_threshold, number_threshold = 0.4, 0.6, 50\n",
        "\n",
        "# first iteration\n",
        "lr = LogisticRegressionCV(first_threshold)\n",
        "best_score = np.mean(cross_val_score(lr, X_all, t_all, cv=folds, scoring=scorer))\n",
        "best_threshold = first_threshold\n",
        "\n",
        "thresholds = []\n",
        "scores = []\n",
        "\n",
        "# iterations where the threshold varies\n",
        "for threshold in np.linspace(first_threshold, last_threshold, number_threshold):\n",
        "    lr = LogisticRegressionCV(threshold)\n",
        "    mean_score = np.mean(cross_val_score(lr, X_all, t_all, cv=folds, scoring=scorer))\n",
        "    \n",
        "    thresholds.append(threshold)\n",
        "    scores.append(mean_score)\n",
        "    \n",
        "    if(mean_score < best_score):\n",
        "        best_threshold = threshold\n",
        "        best_score = mean_score\n",
        "\n",
        "print(f\"The lowest error rate {round(best_score*100, 2)}% was found for threshold {round(best_threshold, 3)}.\")\n",
        "\n",
        "plt.title(\"Variation of the mean score in cross-validation depending on the threshold\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"Mean error rate\")\n",
        "plt.plot(thresholds, scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With cross-validation we find that a threshold under the \"default\" of 0.5 gives better results on average.\n",
        "\n",
        "We will now retry to predict the classification on the initial test set using this optimized threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_best = LogisticRegressionCV(best_threshold).fit(X, t)\n",
        "\n",
        "x1_bounds=(-2.5, 1.5)\n",
        "x2_bounds=(-1, 5)\n",
        "figsize=(20,5)\n",
        "\n",
        "cv_classification = BinaryPointsClassification(X_test, t_test, lr_best.predict)\n",
        "cv_classification.display_prediction(x1_bounds, x2_bounds, resolution = 1000, title = f\"Test set classification with optimized threshold (error rate: {cv_classification.error_rate*100}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previously, the error rate was 6%. Now it has gone down to 5.5%: the threshold optimization helped improving the results.\n",
        "\n",
        "To have even more precise results, with more time we could try to re-run the cross-validation with a number of folds equal to the dataset size, which could possibly help find an even better threshold."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Application: handwritten digits recognition 5 & 6\n",
        "We load 2 matrices which contain each a sequence of examples of 16x16 images \n",
        "of handwritten digits which are 5 and 6 here. Each line of the matrix\n",
        "contains 256 pixel values coding for the gray level of a 16x16 image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_5 = np.loadtxt('train_5.txt',delimiter=',')   # 556 samples\n",
        "train_6 = np.loadtxt('train_6.txt',delimiter=',')   # 664 samples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examples of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Digit 5\n",
        "n=9\n",
        "I = np.reshape(train_5[n,:],(16,16))\n",
        "\n",
        "plt.imshow(I,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Digit 6\n",
        "n=4\n",
        "I = reshape(train_6[n,:],(16,16))\n",
        "\n",
        "plt.imshow(I,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separating the training and test sets\n",
        "\n",
        "We keep in the training set the 145 first images of 5s and the 200 first\n",
        "images of 6s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_brut = np.vstack((train_5[:145,:], train_6[:200,:]))\n",
        "N_train = np.size(x_train_brut,axis=0)\n",
        "class_train = np.ones((345,)) # label 1 for digit 6\n",
        "class_train[:145] = 0 # label 0 for digit 5\n",
        "\n",
        "x_test_brut = np.vstack((train_5[145:,:], train_6[200:,:]))\n",
        "N_test = np.size(train_5,axis=0)+np.size(train_6,axis=0)-N_train\n",
        "class_test = np.ones((875,)) # label 1 for digit 6\n",
        "class_test[:410] = 0 # label 0 for digit 5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: logistic regression to classify 5 & 6\n",
        "\n",
        "1. Note that pixel values are between -1 and 1 by using the functions\n",
        " `min(I(:))` and `max(I(:))`.\n",
        "2. Identify the indices of the most significant pixels, which are defined \n",
        "as having a standard deviation greater than 0.5 here. We denote by `lis_sig`\n",
        "the list of positions of these significant pixels in the image vector.\n",
        "_Indication : the function `std` gives the standard deviation (columnwise\n",
        "in matrices) and you should find 173 pixel positions.\n",
        "3. Show a binary image to locate these pixels.\n",
        "_Indication : `Isig = zeros(16); Isig(list_sig)=1; Isig=Isig';`._\n",
        "4. Define the training set `x_train` from `x_train_brut` from the significant pixels only.\n",
        "5. Do the same with `x_test_brut` to extract `x_test`.\n",
        "6. Use `regression_logistique.m` to estimate the logistic regression vector\n",
        "`w` from the training set `x_train`. \n",
        "Choose `Nitermax = 13; eps_conv = 1e-3;`\n",
        "7. Compute the decision function and the labels of the test set `x_test`. \n",
        "_Indication : do not forget the column of ones !_\n",
        "8. Estimate the classification error rate by using :\n",
        "`erreur = sum(abs(class-class_test))/N_test;`.\n",
        "9. Locate some misclassified examples and visualize the corresponding image.\n",
        "Comment on your results and observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q1: Minimum and maximum pixel values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"The pixel values are between {np.min(I[:])} and {np.max(I[:])}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q2: Identify the most significant pixels + Q3: Display a binary image to locate these pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "std = np.std(x_train_brut, axis=0)\n",
        "\n",
        "I_std_heat = std.reshape((16,16))\n",
        "\n",
        "std_bin = np.array([std>0.5])[0]\n",
        "I_std_bin = std_bin.reshape((16,16))\n",
        "\n",
        "plt.figure(figsize=(13,4.6))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Standard deviation for each pixel over the entire dataset\")\n",
        "sns.heatmap(I_std_heat)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(f\"Display of the {sum(std_bin)} most important pixels (std>0.5)\")\n",
        "sns.heatmap(I_std_bin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pixels that have the highest standard deviation are located in such a way that we could fit 5's and 6's in the \"silhouette\" that is produced from the heatmap. Understandably, we recognize the round shape that is common to 5 and 6 at the bottom of the image, among other common features. This translates well the fact that those pixels are the ones that are important to look at when it comes to identifying the two numbers.\n",
        "\n",
        "Out of curiosity, we also display the most significant pixels for 5's and 6's individually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "std_5 = np.std(train_5, axis=0)\n",
        "std_6 = np.std(train_6, axis=0)\n",
        "\n",
        "plt.figure(figsize=(13,4.6))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Standard deviation for each pixel in the 5's dataset\")\n",
        "sns.heatmap(std_5.reshape((16,16)))\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Standard deviation for each pixel in the 6's dataset\")\n",
        "sns.heatmap(std_6.reshape((16,16)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expectedly, we observe that the \"significant\" (high variance) features are different from the heatmap observed before: each number is represented more accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q4 and Q5: Define the training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train_brut[:, std_bin]\n",
        "x_test = x_test_brut[:, std_bin]\n",
        "\n",
        "print(f\"The number of columns in x_train was reduced to {x_train.shape[1]}.\")\n",
        "print(f\"The number of columns in x_test was reduced to {x_test.shape[1]}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q6: Estimate the logistic regression vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Nitermax = 13\n",
        "eps_conv = 1e-3\n",
        "\n",
        "x_train_t = np.hstack((np.ones((N_train,1)),x_train)) # 't' for 'tilde' since we are adding a column of 1's\n",
        "x_test_t = np.hstack((np.ones((N_test,1)),x_test))\n",
        "\n",
        "logRegNumbers = LogisticRegression(x_train_t, class_train, Nitermax = Nitermax, eps_conv = eps_conv)\n",
        "\n",
        "# The logistic regression vector is given by\n",
        "w = logRegNumbers.coefs\n",
        "\n",
        "print(f\"The logistic regression vector is of shape {w.shape} (includes coefs for 173 most significant pixels and bias)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note on `Nitermax` and `eps_conv`: we inadvertently had forgotten to use the recommended values, which resulted in an error thrown by `regression_logistique`: \"Not a Singular Matrix\". This highlights the importance of these parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q7: Compute the prediction + Q8: Estimate the error rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = logRegNumbers.predict(x_test_t)\n",
        "\n",
        "error = sum(abs(prediction-class_test))/N_test\n",
        "print(f\"The estimated error rate for the numbers prediction is {error*100}%.\")\n",
        "\n",
        "skl.metrics.ConfusionMatrixDisplay.from_predictions(class_test, prediction, cmap=plt.cm.Purples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The confusion matrix shows that the predictor made 70 mistakes:\n",
        "- 45 5's were labelled as 6's, which represents an error rate of $45/410 \\approx 11 \\%$\n",
        "- 25 6's were labelled as 5's, which represents an error rate of $25/465 \\approx 5.4 \\%$\n",
        "  \n",
        "Meaning that proportionally, more mistakes were made on 5's. This result seems to reflect the fact that there were more 6's than 5's (over 30% more, in fact) in the training set. This results in a system that seems very capable of recognizing 6's, but has been insufficiently trained to recognize 5's: it is a form of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q9: Display and comment on some of the mistakes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "error_mask = abs(prediction-class_test)\n",
        "error_mask = error_mask.astype(int)\n",
        "mistakes = x_test_brut[error_mask==1]\n",
        "\n",
        "def display_image(data, index):\n",
        "    img = reshape(data[index,:],(16,16))\n",
        "    plt.imshow(img,cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb_to_display = 9 # must be lower than 10 for the next loops to manage subplots properly\n",
        "offset = 0 # modify to display different parts of the misclassed numbers (must not be too high)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "for i in range(1, nb_to_display+1):\n",
        "    plt.subplot(100 + nb_to_display*10 + i)\n",
        "    display_image(mistakes, offset + i) # the first elements are wrongly guessed 5's\n",
        "    \n",
        "    \n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(1, nb_to_display+1):\n",
        "    plt.subplot(100 + nb_to_display*10 + i)\n",
        "    display_image(mistakes, -offset - i) # the last elements are wrongly guessed 6's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From a very subjective point of view, it seems understandable that some of the above 5's were mistaken for 6's. For the first ones in particular, the \"gap\" to the bottom left is sometimes very small, which could be a reason to mistake a 5 for a 6. For the 6's that were mistaken as 5's, the prediction seems to make a little less sense. On the sample of mistakes we drew, most of them seem to have in common a \"counter-clockwise rotation\", which is hard to interpret without studying the training set in more depth."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Logistic regression using `scikit-learn`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Go to** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html for a presentation of the logistic regression model in `scikit-learn`.\n",
        "\n",
        "2. **Apply** it to the present data set.\n",
        "\n",
        "3. **Comment** on the use of logistic regression.\n",
        "\n",
        "*Indication : you may have a look at* \n",
        "\n",
        "a) Theory : http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex5/ex5.html\n",
        "\n",
        "b) Video :  https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression \n",
        "\n",
        "c) Example : http://scikit-learn.org/stable/auto_examples/exercises/plot_digits_classification_exercise.html#sphx-glr-auto-examples-exercises-plot-digits-classification-exercise-py\n",
        "\n",
        "*for a short presentation of regularized logistic regression.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear regression with penalty\n",
        "from sklearn.linear_model import LogisticRegression as SkLearnLogisticRegression\n",
        "sk_learn_lr = SkLearnLogisticRegression().fit(x_train_t, class_train)\n",
        "prediction_sklearn = sk_learn_lr.predict(x_test_t)\n",
        "\n",
        "error_sklearn = sum(abs(prediction_sklearn-class_test))/N_test\n",
        "print(f\"With sklearn, the estimated error rate for the numbers of prediction is {error_sklearn*100}%.\")\n",
        "\n",
        "skl.metrics.ConfusionMatrixDisplay.from_predictions(class_test, prediction_sklearn, cmap=plt.cm.Purples)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that sklearn manages to make better prediction than our own implementation of logistic regression. Indeed, sklearn uses regularized logistic regression which helps reduce the overfitting caused by the imbalance between the number of 5s and the number of 6s. \n",
        "\n",
        "Let's compute sklearn's logistic regression without penalty to make sure that regularization is actually what improves the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear regression without penalty\n",
        "sk_learn_lr_no_penalty = SkLearnLogisticRegression(penalty='none').fit(x_train_t, class_train)\n",
        "prediction_sklearn_no_penalty = sk_learn_lr_no_penalty.predict(x_test_t)\n",
        "\n",
        "error_sklearn_no_penalty = sum(abs(prediction_sklearn_no_penalty-class_test))/N_test\n",
        "print(f\"With sklearn without the penalty, the estimated error rate for the numbers of prediction is {error_sklearn_no_penalty*100}%.\")\n",
        "\n",
        "skl.metrics.ConfusionMatrixDisplay.from_predictions(class_test, prediction_sklearn_no_penalty, cmap=plt.cm.Purples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that, as expected, sklearn's prediction is slightly worse without regularization. However, it is still better than ours: it might be because sklearn uses some kind of optimization to improve predictions (e.g. an optimization of the threshold), or because of an implementation error on our part."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "eddbe03df7610b6ab8092acf41ddda77de6230c42b3d7be1a47827e0e54e49a3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('sdia-decision': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
