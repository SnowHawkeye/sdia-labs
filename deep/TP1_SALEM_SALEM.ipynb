{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 : Logistic regression by gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etudiant 1 : Emilie SALEM\n",
    "## Etudiant 2 : Hadrien SALEM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(nb_points):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for _ in range(nb_points):\n",
    "        x1, x2 = np.random.uniform(low = 0, high = 1, size = 2)\n",
    "        D = (0.5*x1 + x2 - 0.75) / np.sqrt(0.5**2 + 1)\n",
    "        if D > 0 : label = 1\n",
    "        else : label = 0\n",
    "        r = np.exp(-D**2/(2*0.05**2))\n",
    "        z = np.random.binomial(1, r/2)\n",
    "        if(z==1):\n",
    "            if label == 1 : label = 0\n",
    "            else: label = 1\n",
    "        point = np.array([x1, x2])\n",
    "        data.append(point)\n",
    "        labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels = datagen(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = X[labels == 0]\n",
    "class1 = X[labels == 1]\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(class0[:,0], class0[:,1], c='r')\n",
    "plt.scatter(class1[:,0], class1[:,1], c='b')\n",
    "plt.legend([\"Class 0\", \"Class 1\"])\n",
    "plt.title(\"Distribution des points dans les classes 0 et 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plus = np.hstack((np.ones((X.shape[0],1)), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgm(x): return 1/(1+np.exp(-x))\n",
    "\n",
    "def gradient_descent(X_plus, labels, learn_rate, iter_max):\n",
    "    theta = np.random.rand(3)\n",
    "    \n",
    "    history = [theta]\n",
    "    pred = sgm(X_plus.dot(theta)).reshape(300,)\n",
    "    err = pred - labels \n",
    "    g = X_plus.T.dot(err)\n",
    "    theta_new = theta - learn_rate*g\n",
    "    history.append(theta_new)\n",
    "    N_iter = 1\n",
    "    \n",
    "    while((np.linalg.norm(theta_new-theta) > 10e-8) and (N_iter < iter_max)):\n",
    "        N_iter += 1\n",
    "        theta = theta_new\n",
    "        pred = sgm(X_plus.dot(theta)).reshape(300,)\n",
    "        err = pred - labels \n",
    "        g = X_plus.T.dot(err)\n",
    "        theta_new = theta - learn_rate*g\n",
    "        history.append(theta_new)\n",
    "        \n",
    "    return history[-1], np.array(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_descent(thetas) :\n",
    "    fig = plt.figure(figsize=((7,7)))\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "    ax.plot(thetas[:,0],thetas[:,1],thetas[:,2],\"-o\")\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un learning rate de 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, thetas = gradient_descent(X_plus, labels, 0.02, 50000)\n",
    "print(\"Nombre d'itérations : \" + str(len(thetas)))\n",
    "display_descent(thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un learning rate de 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, thetas = gradient_descent(X_plus, labels, 0.1, 50000)\n",
    "print(\"Nombre d'itérations : \" + str(len(thetas)))\n",
    "display_descent(thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "\n",
    "On observe qu'avec un learning rate plus important, on fait des pas de gradient plus grands : il y a plus d'oscillations et on risque de ne pas converger, mais si on converge effectivement la solution est atteinte bien plus vite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_boundary(theta):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(class0[:,0], class0[:,1], c='r')\n",
    "    plt.scatter(class1[:,0], class1[:,1], c='b')\n",
    "    plt.title(\"Distribution des points dans les classes 0 et 1 + Prédiction\")\n",
    "\n",
    "    x1 = np.linspace(0,1,10) \n",
    "    x2 = (-theta[0]-theta[1]*x1)/theta[2]\n",
    "    plt.plot(x1,x2,'k--')\n",
    "\n",
    "    plt.legend([\"Frontière de décision\", \"Class 0\", \"Class 1\"])\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9963137a101e18cad171261b7fa1fb03f34a5ba10ba22de7f6ebf9ccd0228ae6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python-all': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
