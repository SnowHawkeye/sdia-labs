{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Deep learning - Practical nÂ°2"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Student 1 : Emilie SALEM\n",
        "## Student 2 : Hadrien SALEM "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Preliminaries"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import numpy as np\n",
        "from sklearn.datasets import make_circles\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count":580,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Generation and display of the dataset\n",
        "\n",
        "X,y = make_circles(n_samples = 300, noise=0.2, factor=0.1)\n",
        "n,d = X.shape\n",
        "plt.figure(1,figsize=[6,6])\n",
        "plt.plot(X[:,0][np.where(y==1)],X[:,1][np.where(y==1)],\".c\")\n",
        "plt.plot(X[:,0][np.where(y==0)],X[:,1][np.where(y==0)],\".m\")"
      ],
      "execution_count":581,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "[<matplotlib.lines.Line2D at 0x7fb57dd6a370>]"
            ],
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Utility functions\n",
        "\n",
        "def sigmoid(x):\n",
        "    res = 1 \/ (1 + np.exp(-x))\n",
        "    return res\n",
        "\n",
        "def onehot(y,i):\n",
        "    \"\"\"Creates a one-hot encoding of the i element of y\"\"\"\n",
        "    return 1-np.array(list(bin(y[i]+1)[2:].zfill(2))).astype(int)"
      ],
      "execution_count":582,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Exercise 1: Network creation"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Definition of an input unit\n",
        "class InputUnit:\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,data):\n",
        "        self.data = data # one column of matrix X\n",
        "        self.n = data.shape[0] # dataset size\n",
        "        self.k = 0 # layer number\n",
        "        self.z = 0 # unit output\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Input unit in layer {self.k}, containing {self.n} examples.\"\n",
        "\n",
        "    def plug(self, unit):\n",
        "        unit.preceding.append(self)\n",
        "\n",
        "    def forward(self,i):\n",
        "        self.z = self.data[i]\n",
        "        return self.z"
      ],
      "execution_count":583,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Creation of 2 input units, one for each column of X\n",
        "input_unit_1 = InputUnit(X[:,0])\n",
        "input_unit_2 = InputUnit(X[:,1])"
      ],
      "execution_count":584,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Definition of a neural unit\n",
        "class NeuralUnit:\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self,k,u):\n",
        "        self.u = u # unit number\n",
        "        self.preceding = [] # list of preceding neurons\n",
        "        # self.npr = 0 # length of list preceding\n",
        "        self.following = [] # list of following neurons\n",
        "        # self.nfo = 0 # length of list following\n",
        "        self.k = k # layer number\n",
        "        self.w = 0 # unit weights\n",
        "        self.b = 0 # unit intercept\n",
        "        self.z = 0 # unit output\n",
        "        self.delta = np.zeros(np.shape(self.w))\n",
        "        self.w_grad = np.zeros(np.shape(self.w))\n",
        "        self.b_grad = 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Neural unit #{self.u} in layer {self.k} with {self.npr} preceding element(s) and {self.nfo} following element(s).\"\n",
        "\n",
        "    @property # custom getter for length of list preceding\n",
        "    def npr(self):\n",
        "        return len(self.preceding)\n",
        "\n",
        "    @property # custom getter for length of list following\n",
        "    def nfo(self):\n",
        "        return len(self.following)\n",
        "\n",
        "    def reset_params(self):\n",
        "        self.w = np.random.randn(self.npr)\n",
        "        self.b = np.random.randn()\n",
        "\n",
        "    def plug(self, unit):\n",
        "        unit.preceding.append(self)\n",
        "        self.following.append(unit)\n",
        "\n",
        "    def forward(self, i):\n",
        "        z_in = np.zeros(self.npr)\n",
        "        for index, unit in enumerate(self.preceding) :\n",
        "            z_in[index] = unit.forward(i)\n",
        "        self.z = sigmoid(self.w.dot(z_in) + self.b)\n",
        "        return self.z\n",
        "\n",
        "    def backprop(self, i, deltas):\n",
        "        self.delta = np.zeros(np.shape(self.w))\n",
        "        self.w_grad = np.zeros(np.shape(self.w))\n",
        "        delta_u = deltas[self.u]\n",
        "        for v in range(self.npr):\n",
        "            self.delta[v] = (self.z*(1 - self.z)*self.w[v])*delta_u\n",
        "            self.w_grad[v] = self.preceding[v].z*self.z*(1-self.z)*delta_u\n",
        "        self.b_grad = self.z*(1-self.z)*delta_u"
      ],
      "execution_count":585,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "execution_count":585,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Creation of the 3 neural units corresponding to this problem\n",
        "\n",
        "# Layer 1\n",
        "neural_unit_11 = NeuralUnit(1, 1)\n",
        "neural_unit_12 = NeuralUnit(1, 2)\n",
        "\n",
        "# Layer 2\n",
        "neural_unit_21 = NeuralUnit(2, 1)"
      ],
      "execution_count":586,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "class Loss:\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,y,k):\n",
        "        self.preceding = [] # list of preceding neurons\n",
        "        # self.npr = 0 # length of list preceding\n",
        "        self.y = y # array of class labels of the training data\n",
        "        self.k = k # layer index\n",
        "        self.delta = np.zeros((1,))\n",
        "            \n",
        "    def __str__(self):\n",
        "        return f\"Loss unit in layer {self.k} with {self.npr} preceding element(s).\"\n",
        "\n",
        "    @property # custom getter for length of list preceding\n",
        "    def npr(self):\n",
        "        return len(self.preceding)\n",
        "\n",
        "    def forward(self, i):\n",
        "        z_in = self.preceding[0].forward(i)\n",
        "        if self.y[i] == 0 : return -np.log(1-z_in)\n",
        "        else : return -np.log(z_in)\n",
        "            \n",
        "    def backprop(self, i):\n",
        "        z_in = self.preceding[0].z\n",
        "        if self.y[i] == 0 : self.delta[0] = 1\/(1-z_in)\n",
        "        else : self.delta[0] = -1\/z_in"
      ],
      "execution_count":587,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Creation of the loss unit\n",
        "loss_unit = Loss(y, 3)"
      ],
      "execution_count":588,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "class MLP:\n",
        "    # Constructor\n",
        "    def __init__(self,X,y,archi):\n",
        "        self.archi = archi\n",
        "        self.X = X\n",
        "        self.n = X.shape[0]\n",
        "        self.y = y\n",
        "        self.K = len(archi) # number of layers (including the input layer but without the loss layer)\n",
        "\n",
        "        # Creating network\n",
        "        net = []\n",
        "\n",
        "        # Inputs\n",
        "        n_inputs = archi[0]\n",
        "        input_layer = []\n",
        "        for i in range(n_inputs):\n",
        "            input_layer.append(InputUnit(X[:,i]))\n",
        "        net.append(input_layer)\n",
        "            \n",
        "        # Neural units\n",
        "        for k in range(1, self.K) :\n",
        "            layer = []\n",
        "            n_units = archi[k]\n",
        "            for j in range(n_units):\n",
        "                layer.append(NeuralUnit(k,j))\n",
        "            net.append(layer)\n",
        "\n",
        "        # Loss\n",
        "        loss_layer = [Loss(y, self.K)]\n",
        "        net.append(loss_layer)\n",
        "\n",
        "        # Plugging units together and resetting parameters\n",
        "        for k in range(len(net) - 1):\n",
        "            for unit in net[k] :\n",
        "                if isinstance(unit, NeuralUnit) : unit.reset_params()\n",
        "                for next_unit in net[k+1]:\n",
        "                    unit.plug(next_unit)\n",
        "\n",
        "        self.net = net\n",
        "\n",
        "    def forward(self,i):\n",
        "        return self.net[-1][0].forward(i)\n",
        "\n",
        "    def backprop(self, i):\n",
        "        # first iteration: loss layer\n",
        "        self.net[-1][0].backprop(i)\n",
        "        deltas = self.net[-1][0].delta\n",
        "\n",
        "        for k in range(len(self.net)-2, 0, -1):\n",
        "            deltas_new = np.zeros((self.net[k][0].npr,))\n",
        "            for u in range(len(self.net[k])):\n",
        "                self.net[k][u].backprop(i,deltas)\n",
        "                deltas_new += self.net[k][u].delta\n",
        "            deltas = deltas_new\n",
        "\n",
        "    def update(self, eta):\n",
        "        for k in range(1, len(self.net) - 1):\n",
        "            for unit in self.net[k]:\n",
        "                unit.w -= eta * unit.w_grad\n",
        "                unit.b -= eta * unit.b_grad\n",
        "    \n",
        "    def train(self, epochs,eta):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(self.n):\n",
        "                self.forward(i)\n",
        "                self.backprop(i)\n",
        "                self.update(eta)"
      ],
      "execution_count":589,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Instanciation of the network corresponding to our problem\n",
        "archi = [2,2,1]\n",
        "mlp = MLP(X,y,archi)\n",
        "\n",
        "# Check unit connections and parameters initialization\n",
        "for layer in mlp.net :\n",
        "    for unit in layer :\n",
        "        print(unit)"
      ],
      "execution_count":590,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Input unit in layer 0, containing 300 examples.\n",
            "Input unit in layer 0, containing 300 examples.\n",
            "Neural unit #0 in layer 1 with 2 preceding element(s) and 1 following element(s).\n",
            "Neural unit #1 in layer 1 with 2 preceding element(s) and 1 following element(s).\n",
            "Neural unit #0 in layer 2 with 2 preceding element(s) and 1 following element(s).\n",
            "Loss unit in layer 3 with 1 preceding element(s).\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Exercise 2: Forward pass"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We programmed the `forward(self,i)` functions in all the above classes (different types of units and `MLP`)."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Checking that the forward methods are correctly programmed\n",
        "\n",
        "index_0 = 0 # index of an element for which y = 0\n",
        "loss_0 = mlp.forward(index_0)\n",
        "output_neural_0 = mlp.net[2][0].z # output of the last neural unit of the network\n",
        "print(f\"For an example of class 0, the output of the last neural unit is {output_neural_0} and the loss is {loss_0}.\")\n",
        "\n",
        "\n",
        "index_1 = 45 # index of an element for which y = 1\n",
        "loss_1 = mlp.forward(index_1)\n",
        "output_neural_1 = mlp.net[2][0].z\n",
        "print(f\"For an example of class 1, the output of the last neural unit is {output_neural_1} and the loss is {loss_1}.\")"
      ],
      "execution_count":591,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "For an example of class 0, the output of the last neural unit is 0.6293400144812036 and the loss is 0.9924701176816716.\n",
            "For an example of class 1, the output of the last neural unit is 0.5182646911910189 and the loss is 0.730360467619225.\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "These tests allow us to check that the loss is higher when the prediction of the network is wrong : the forward functions seem to be programmed properly."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Exercise 3: Backprop"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We added `backprop` methods to the `Loss` and `NeuralUnit` classes."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Testing the computed gradients\n",
        "i = 0\n",
        "archi = [d,10,1]\n",
        "mlp = MLP(X,y,archi)\n",
        "mlp.forward(i)\n",
        "mlp.backprop(i)\n",
        "epsi=1e-3\n",
        "mlp2 = copy.deepcopy(mlp)\n",
        "mlp2.net[1][0].w[0] = mlp.net[1][0].w[0] + epsi\n",
        "print(\"numerical derivative is:\",(mlp2.forward(i) - mlp.forward(i))\/epsi)\n",
        "print(\"computed derivative is:\",mlp.net[1][0].w_grad[0])"
      ],
      "execution_count":592,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "numerical derivative is: -0.002565106453800148\n",
            "computed derivative is: -0.002564749334484727\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "The numerical derivatives are very close to the computed ones: it seems that our implementation is correct."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Exercise 4 : SGD training of the network"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We implemented an `update` and a `train` method in the `MLP` class."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Training the mlp\n",
        "mlp.train(50,0.01)"
      ],
      "execution_count":596,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}